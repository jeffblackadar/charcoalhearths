{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "j23yFos2S1SK",
    "outputId": "4599490b-a651-4bc3-ca8a-65311795fe3b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/student/data_5000_project/programs/R-CNN\n",
      "/home/student/data_5000_project/programs/R-CNN\r\n"
     ]
    }
   ],
   "source": [
    "#Set up the directory\n",
    "new_dir = \"/home/student/data_5000_project/programs/R-CNN/\"\n",
    "%cd $new_dir\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9X9YAGNITP3q",
    "outputId": "44e63492-d2d6-4b8d-c895-c2374fec8b31",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.6.10 :: Anaconda, Inc.\r\n"
     ]
    }
   ],
   "source": [
    "!python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "1esOiePJUL_d",
    "outputId": "db733564-9921-4d31-96ec-99571005d047"
   },
   "source": [
    "Run\n",
    "!sudo git clone https://github.com/matterport/Mask_RCNN.git\n",
    "\n",
    "Data is in \n",
    "/home/student/data_5000_project/data/images/construction_types/processed/opus_incertum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "o8583CRd-vAW",
    "outputId": "4d287e08-710d-47ee-bd8e-a1ccff37614e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pwd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "JJWsC0f0-8e0",
    "outputId": "39b710ed-eac9-4e76-efbe-03de003b5d5e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#if not /home/student/data_5000_project/programs/R-CNN/Mask_RCNN\n",
    "%cd Mask_RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 714
    },
    "colab_type": "code",
    "id": "t92IBbZdVgwI",
    "outputId": "f1db0549-1343-4402-a278-191366ce52a1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python setup.py install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "FA7900MLVssa",
    "outputId": "d7037dc5-40bc-4df5-b688-5a500f0dc9ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: mask-rcnn\n",
      "Version: 2.1\n",
      "Summary: Mask R-CNN for object detection and instance segmentation\n",
      "Home-page: https://github.com/matterport/Mask_RCNN\n",
      "Author: Matterport\n",
      "Author-email: waleed.abdulla@gmail.com\n",
      "License: MIT\n",
      "Location: /home/student/anaconda3/envs/tensorflow/lib/python3.6/site-packages/mask_rcnn-2.1-py3.6.egg\n",
      "Requires: \n",
      "Required-by: \n",
      "/home/student/data_5000_project/programs/R-CNN/Mask_RCNN\n"
     ]
    }
   ],
   "source": [
    "!pip show mask-rcnn\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "id": "rIUVKE7tWPZk",
    "outputId": "93152227-31f5-4e9e-813c-5addd5ab2a83",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charcoal_hearth_hill\n",
      "Train: 250\n",
      "Test: 30\n"
     ]
    }
   ],
   "source": [
    "# split into train and test set\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "#construction_type = \"opus_latericium_-_opus_testaceum\"\n",
    "#test_train_split = 70\n",
    "#construction_type = \"opus_vittatum_mixtum\"\n",
    "#test_train_split = 65\n",
    "construction_type = \"charcoal_hearth_hill\"\n",
    "test_train_split = 581208\n",
    "#construction_type = \"opus_incertum\"\n",
    "#test_train_split = 602\n",
    "# class that defines and loads the opus_incertum dataset\n",
    "class ObjectDataset(Dataset):\n",
    "    # load the dataset definitions\n",
    "    def load_dataset(self, dataset_dir, is_train=True):\n",
    "        # define one class\n",
    "        self.add_class(\"dataset\", 1, construction_type)\n",
    "        # define data locations\n",
    "        images_dir = dataset_dir + '/images_training/'\n",
    "        #basic training\n",
    "        #annotations_dir = dataset_dir + '/annots/'\n",
    "        #training on annotations made after a model did predictions\n",
    "        annotations_dir = '/storage/images/charcoal_hearth_hill/predictions/cfg20200624T1134/unknown/edited/fixed/'\n",
    "        # find all images\n",
    "        for filename in listdir(images_dir):\n",
    "            # extract image id\n",
    "            image_id = filename[:-4]\n",
    "            \n",
    "            # skip all images after 400 if we are building the train set\n",
    "            #if is_train and int(image_id) >= 602:\n",
    "            #if is_train and int(image_id) >= 79:\n",
    "            if is_train and int(image_id) >= test_train_split:\n",
    "                continue\n",
    "            # skip all images before 400 if we are building the test/val set\n",
    "            #if not is_train and int(image_id) < 602:\n",
    "            #if not is_train and int(image_id) < 79:\n",
    "            if not is_train and int(image_id) < test_train_split:\n",
    "                continue\n",
    "            img_path = images_dir + filename\n",
    "            ann_path = annotations_dir + image_id + '.xml'\n",
    "            # add to dataset\n",
    "            self.add_image('dataset', image_id=image_id, path=img_path, annotation=ann_path)\n",
    "\n",
    "    # extract bounding boxes from an annotation file\n",
    "    def extract_boxes(self, filename):\n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            xmin = int(box.find('xmin').text)\n",
    "            ymin = int(box.find('ymin').text)\n",
    "            xmax = int(box.find('xmax').text)\n",
    "            ymax = int(box.find('ymax').text)\n",
    "            coors = [xmin, ymin, xmax, ymax]\n",
    "            boxes.append(coors)\n",
    "        # extract image dimensions\n",
    "        width = int(root.find('.//size/width').text)\n",
    "        height = int(root.find('.//size/height').text)\n",
    "        return boxes, width, height\n",
    "\n",
    "    # count bounding boxes from an annotation file\n",
    "    def count_boxes(self, filename):\n",
    "        # load and parse the file\n",
    "        tree = ElementTree.parse(filename)\n",
    "        # get the root of the document\n",
    "        root = tree.getroot()\n",
    "        # extract each bounding box\n",
    "        boxes = list()\n",
    "        box_count=0\n",
    "        for box in root.findall('.//bndbox'):\n",
    "            box_count=box_count+1\n",
    "        return box_count\n",
    "\n",
    "    \n",
    "    # load the masks for an image\n",
    "    def load_mask(self, image_id):\n",
    "        # get details of image\n",
    "        info = self.image_info[image_id]\n",
    "        # define box file location\n",
    "        path = info['annotation']\n",
    "        # load XML\n",
    "        boxes, w, h = self.extract_boxes(path)\n",
    "        # create one array for all masks, each on a different channel\n",
    "        masks = zeros([h, w, len(boxes)], dtype='uint8')\n",
    "        # create masks\n",
    "        class_ids = list()\n",
    "        for i in range(len(boxes)):\n",
    "            box = boxes[i]\n",
    "            row_s, row_e = box[1], box[3]\n",
    "            col_s, col_e = box[0], box[2]\n",
    "            masks[row_s:row_e, col_s:col_e, i] = 1\n",
    "            class_ids.append(self.class_names.index(construction_type))\n",
    "        return masks, asarray(class_ids, dtype='int32')\n",
    "\n",
    "    # load an image reference\n",
    "    def image_reference(self, image_id):\n",
    "        info = self.image_info[image_id]\n",
    "        return info['path']\n",
    "print(construction_type)\n",
    "# train set\n",
    "train_set = ObjectDataset()\n",
    "# opus_incertum - change\n",
    "train_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "\n",
    "# test/val set\n",
    "test_set = ObjectDataset()\n",
    "# opus_incertum - change\n",
    "test_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count Boxes for Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "charcoal_hearth_hill\n",
      "Train data set of images\n",
      "Train images: 250\n",
      "Train boxes: 2264\n",
      "Train set: 250 [2264]\n",
      "train_STEPS_PER_EPOCH = 250\n",
      "Test data set of images\n",
      "Test images: 30\n",
      "Test boxes: 182\n",
      "Test set: 30 [182]\n",
      "test_VALIDATION_STEPS = 30\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "#print(inspect.getmembers(train_set))\n",
    "#print(train_set)\n",
    "print(construction_type)\n",
    "print(\"Train data set of images\")\n",
    "print('Train images: %d' % len(train_set.image_ids))\n",
    "boxes_total = 0\n",
    "for i in train_set.image_info:\n",
    "    #print(i['annotation'])\n",
    "    boxes_count = train_set.count_boxes(i['annotation'])\n",
    "    boxes_total = boxes_total + boxes_count\n",
    "    #print(boxes_count)\n",
    "print('Train boxes: %d' % boxes_total)\n",
    "print('Train set: %d [%d]' %( len(train_set.image_ids), boxes_total))\n",
    "train_STEPS_PER_EPOCH = len(train_set.image_ids)\n",
    "print(\"train_STEPS_PER_EPOCH =\",train_STEPS_PER_EPOCH)\n",
    "\n",
    "\n",
    "print(\"Test data set of images\")\n",
    "print('Test images: %d' % len(test_set.image_ids))\n",
    "boxes_total = 0\n",
    "for i in test_set.image_info:\n",
    "    #print(i['annotation'])\n",
    "    boxes_count = train_set.count_boxes(i['annotation'])\n",
    "    boxes_total = boxes_total + boxes_count\n",
    "    #print(boxes_count)\n",
    "print('Test boxes: %d' % boxes_total)\n",
    "print('Test set: %d [%d]' %( len(test_set.image_ids), boxes_total))\n",
    "\n",
    "test_VALIDATION_STEPS = len(test_set.image_ids)\n",
    "print(\"test_VALIDATION_STEPS =\",test_VALIDATION_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "id": "DuFhFNaMWZSZ",
    "outputId": "339463c0-7394-4ea0-b19d-fd02e1731e6f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(construction_type)\n",
    "# plot one photograph and mask\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from matplotlib import pyplot\n",
    "\n",
    "\n",
    "\n",
    "# train set\n",
    "train_set = ObjectDataset()\n",
    "#opus_incertum\n",
    "train_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=True)\n",
    "train_set.prepare()\n",
    "# load an image\n",
    "image_id = 100\n",
    "image = train_set.load_image(image_id)\n",
    "print(image.shape)\n",
    "# load image mask\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "print(mask.shape)\n",
    "# plot image\n",
    "pyplot.imshow(image)\n",
    "# plot mask\n",
    "pyplot.imshow(mask[:, :, 0], cmap='gray', alpha=0.5)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 756
    },
    "colab_type": "code",
    "id": "m50qRq2pWZlX",
    "outputId": "04fef36f-b2b4-4d09-8a26-2dc571ff965b",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(construction_type)\n",
    "# display image with masks and bounding boxes\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "\n",
    "# train set\n",
    "train_set = ObjectDataset()\n",
    "train_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=True)\n",
    "train_set.prepare()\n",
    "# define image id\n",
    "image_id = 6\n",
    "# load the image\n",
    "image = train_set.load_image(image_id)\n",
    "# load the masks and the class ids\n",
    "mask, class_ids = train_set.load_mask(image_id)\n",
    "# extract bounding boxes from the masks\n",
    "bbox = extract_bboxes(mask)\n",
    "# display image with masks and bounding boxes\n",
    "display_instances(image, bbox, mask, class_ids, train_set.class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run this for cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg_name = 'cfg20200318T1120'\n",
    "cfg_name = ''\n",
    "cfg_name = 'cfg20200321T1454'\n",
    "cfg_name = 'cfg20200321T1851'\n",
    "model_epoch='0005'\n",
    "#lr=0.002\n",
    "cfg_name = 'cfg20200322T1649'\n",
    "cfg_name = 'cfg20200322T1708'\n",
    "model_epoch='0005'\n",
    "#lr=0.004\n",
    "cfg_name = 'cfg20200322T1729'\n",
    "model_epoch='0005'\n",
    "#lr=0.002\n",
    "cfg_name = 'cfg20200322T1741'\n",
    "model_epoch='0020'\n",
    "#lr=0.001 - lr=0.001/10\n",
    "cfg_name = 'cfg20200322T1938'\n",
    "model_epoch='0040'\n",
    "\n",
    "cfg_name = 'cfg20200325T1825'\n",
    "model_epoch='0040'\n",
    "\n",
    "#lr=0.1 - lr=0.1/10\n",
    "cfg_name = 'cfg20200325T1953'\n",
    "model_epoch='0010'\n",
    "\n",
    "#lr=0.001 - lr=0.001/10\n",
    "#Min confidence=9\n",
    "cfg_name = 'cfg20200325T2048'\n",
    "model_epoch='0025'\n",
    "\n",
    "#lr=0.001 - lr=0.001/10\n",
    "#Min confidence=9\n",
    "cfg_name = 'cfg20200401T2134'\n",
    "model_epoch='0025'\n",
    "\n",
    "#lr=0.001 - lr=0.001/10\n",
    "#Min confidence=9\n",
    "\n",
    "cfg_name = 'cfg20200402T0838'\n",
    "model_epoch='0030'\n",
    "\n",
    "#opus_vitatum\n",
    "#lr=0.001 - lr=0.001/10\n",
    "#Min confidence=9\n",
    "\n",
    "cfg_name = 'cfg20200402T1006'\n",
    "model_epoch='0033'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "IuNzDY0qcmqt",
    "outputId": "332883b5-b699-487a-cc16-2c7af1de2900",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# fit a mask rcnn on the opus_incertum dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "\n",
    "print(construction_type)\n",
    "\n",
    "# define a configuration for the model\n",
    "class ObjectConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = construction_type+\"_cfg\"\n",
    "    # number of classes (background + opus_incertum)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    # number of training steps per epoch\n",
    "    STEPS_PER_EPOCH = train_STEPS_PER_EPOCH\n",
    "    VALIDATION_STEPS = test_VALIDATION_STEPS\n",
    "    #LEARNING_RATE = 0.001\n",
    "    LEARNING_RATE = 0.001\n",
    "    DETECTION_MAX_INSTANCES = 9\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "\n",
    "# prepare train set\n",
    "train_set = ObjectDataset()\n",
    "train_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# prepare test/val set\n",
    "test_set = ObjectDataset()\n",
    "test_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# prepare config\n",
    "config = ObjectConfig()\n",
    "config.display()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='training', model_dir='/storage/model/', config=config)\n",
    "# load weights (mscoco) and exclude the output layers\n",
    "model.load_weights('/home/student/data_5000_project/programs/R-CNN/Mask_RCNN/mask_rcnn_coco.h5', by_name=True, exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\",  \"mrcnn_bbox\", \"mrcnn_mask\"])\n",
    "# train weights (output layers or 'heads')\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE, epochs=8, layers='heads')\n",
    "history1 = model.keras_model.history.history \n",
    "#Rosebrock, Adrian. Deep Learning for Computer Vision with Python Vol. 3, Vol. 3. 2019. p360\n",
    "#epochs must be epochs+n below\n",
    "model.train(train_set, test_set, learning_rate=config.LEARNING_RATE /10, epochs=16, layers=\"all\")\n",
    "\n",
    "#Thanks to Renu Khandelwal https://towardsdatascience.com/object-detection-using-mask-r-cnn-on-a-custom-dataset-4f79ab692f6d \n",
    "history2 = model.keras_model.history.history \n",
    "\n",
    "print(\"# \",config.NAME)\n",
    "print(\"# \",construction_type)\n",
    "print(\"# STEPS_PER_EPOCH=\",config.STEPS_PER_EPOCH)\n",
    "print(\"# VALIDATION_STEPS=\",config.VALIDATION_STEPS)\n",
    "print(\"# LEARNING_RATE=\",config.LEARNING_RATE)\n",
    "print(\"# DETECTION_MAX_INSTANCES=\",config.DETECTION_MAX_INSTANCES)\n",
    "\n",
    "\n",
    "print(\"# DETECTION_MIN_CONFIDENCE=\",config.DETECTION_MIN_CONFIDENCE)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history1[\"val_loss\"])\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('history1')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history1[\"loss\"])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('history1')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2[\"val_loss\"])\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('history2')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2[\"loss\"])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('history2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(history1)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history1[\"val_loss\"])\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('history1')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history1[\"loss\"])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('history1')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2[\"val_loss\"])\n",
    "plt.ylabel('val_loss')\n",
    "plt.xlabel('history2')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2[\"loss\"])\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('history2')\n",
    "plt.show()\n",
    "\n",
    "#plt.plot(history2[\"val_loss\"])\n",
    "#plt.ylabel('val_loss')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cfg_name =\"cfg20200628T1152\"\n",
    "model_epoch='0016'\n",
    "#Train mAP: 0.691\n",
    "#Test mAP: 0.795\n",
    "    \n",
    "#This model was used to examine data and prepare for a second training run\n",
    "#cfg_name =\"cfg20200624T1134\"\n",
    "#model_epoch='0016'\n",
    "#Train mAP: 0.605\n",
    "#Test mAP: 0.730\n",
    "\n",
    "#cfg_name =\"cfg20200623T0821\"\n",
    "#model_epoch='0008'\n",
    "#Train mAP: 0.538\n",
    "#Test mAP: 0.638\n",
    "\n",
    "#cfg_name =\"cfg20200623T0821\"\n",
    "#model_epoch='0007'\n",
    "#Train mAP: 0.536\n",
    "#Test mAP: 0.616\n",
    "\n",
    "\n",
    "\n",
    "#cfg_name =\"cfg20200623T0821\"\n",
    "#model_epoch='0009'\n",
    "#Train mAP: 0.513\n",
    "#Test mAP: 0.604\n",
    "\n",
    "#cfg_name =\"cfg20200623T0821\"\n",
    "#model_epoch='0010'\n",
    "#Train mAP: 0.523\n",
    "#Test mAP: 0.642\n",
    "    \n",
    "#cfg_name =\"cfg20200623T0821\"\n",
    "#model_epoch='0060'\n",
    "#Train mAP: 0.425\n",
    "#Test mAP: 0.578\n",
    "\n",
    "#cfg_name =\"cfg20200622T1610\"\n",
    "#model_epoch='0050'\n",
    "#cfg20200622T1610\n",
    "#Re-starting from epoch 50\n",
    "#Train mAP: 0.407\n",
    "#Test mAP: 0.505\n",
    "    \n",
    "#cfg_name =\"cfg20200622T1610\"\n",
    "#model_epoch='0100'\n",
    "#Train mAP: 0.481\n",
    "#Test mAP: 0.493\n",
    "    \n",
    "#cfg_name =\"cfg20200610T1053\"\n",
    "#model_epoch='0040'\n",
    "#Train mAP: 0.550\n",
    "#Test mAP: 0.557\n",
    "\n",
    "#cfg_name =\"cfg20200610T0729\"\n",
    "#model_epoch='0025'\n",
    "#Re-starting from epoch 25\n",
    "#Train mAP: 0.499\n",
    "#Test mAP: 0.568\n",
    "\n",
    "#cfg_name =\"cfg20200610T0729\"\n",
    "#model_epoch='0035'\n",
    "#Train mAP: 0.507\n",
    "#Test mAP: 0.543\n",
    "    \n",
    "#cfg_name =\"cfg20200610T0729\"\n",
    "#model_epoch='0040'\n",
    "#Train mAP: 0.446\n",
    "#Test mAP: 0.545\n",
    "\n",
    "#cfg_name =\"cfg20200610T0729\"\n",
    "#model_epoch='0030'\n",
    "#Re-starting from epoch 30\n",
    "#Train mAP: 0.508\n",
    "#Test mAP: 0.539\n",
    "\n",
    "#cfg_name =\"cfg20200610T0729\"\n",
    "#model_epoch='0060'\n",
    "#Train mAP: 0.491\n",
    "#Test mAP: 0.529\n",
    "\n",
    "#cfg_name =\"cfg20200608T1717\"\n",
    "#model_epoch='0040'\n",
    "#Train mAP: 0.508\n",
    "#Test mAP: 0.543\n",
    "#--------------------------------\n",
    "\n",
    "#  opus_vittatum_cfg\n",
    "#  opus_vittatum\n",
    "# STEPS_PER_EPOCH= 20\n",
    "# VALIDATION_STEPS= 5\n",
    "# LEARNING_RATE= 0.001\n",
    "# DETECTION_MAX_INSTANCES= 9\n",
    "# DETECTION_MIN_CONFIDENCE= 0.9\n",
    "\n",
    "#--------------------------------\n",
    "#cfg_name =\"cfg20200405T1638\"\n",
    "#model_epoch='0040'\n",
    "#  opus_vittatum_mixtum_cfg\n",
    "#  opus_vittatum_mixtum\n",
    "# STEPS_PER_EPOCH= 32\n",
    "# VALIDATION_STEPS= 7\n",
    "# LEARNING_RATE= 0.001\n",
    "# DETECTION_MAX_INSTANCES= 9\n",
    "# DETECTION_MIN_CONFIDENCE= 0.9\n",
    "\n",
    "#cfg_name =\"cfg20200405T1031\"\n",
    "#model_epoch='0040'\n",
    "#opus_latericium_-_opus_testaceum_cfg\n",
    "#opus_latericium_-_opus_testaceum\n",
    "#STEPS_PER_EPOCH 48\n",
    "#VALIDATION_STEPS 12\n",
    "#LEARNING_RATE 0.001\n",
    "#DETECTION_MAX_INSTANCES 9\n",
    "#DETECTION_MIN_CONFIDENCE 0.9\n",
    "\n",
    "#Train: 20\n",
    "#Test: 5\n",
    "#cfg20200402T1006\n",
    "#Re-starting from epoch 33\n",
    "#Train mAP: 0.655\n",
    "#Test mAP: 0.100\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Train: 200\n",
    "#Test: 50\n",
    "#Train: 200\n",
    "#Test: 50\n",
    "#cfg20200402T0838\n",
    "#Re-starting from epoch 30\n",
    "#Train mAP: 0.564\n",
    "#Test mAP: 0.373\n",
    "\n",
    "    \n",
    "\n",
    "#Train: 200\n",
    "#Test: 49\n",
    "#cfg20200401T2134\n",
    "#Re-starting from epoch 25\n",
    "#Train mAP: 0.595\n",
    "#Test mAP: 0.398\n",
    "\n",
    "#============\n",
    "\n",
    "#cfg20200325T2048\n",
    "#Re-starting from epoch 25\n",
    "#Train mAP: 0.634\n",
    "#Test mAP: 0.370\n",
    "\n",
    "\n",
    "#cfg20200325T1953\n",
    "#Re-starting from epoch 10\n",
    "#Train mAP: 0.000\n",
    "#Test mAP: 0.000\n",
    "    \n",
    "#cfg20200325T1953\n",
    "#Re-starting from epoch 25\n",
    "#Train mAP: 0.000\n",
    "#Test mAP: 0.000\n",
    "\n",
    "#cfg20200325T1825\n",
    "#Re-starting from epoch 40\n",
    "#Train mAP: 0.034\n",
    "#Test mAP: 0.025\n",
    "    \n",
    "#cfg20200322T1938\n",
    "#Re-starting from epoch 40\n",
    "#Train mAP: 0.624\n",
    "#Test mAP: 0.345\n",
    "\n",
    "#listed in reverse order of time ... as you can see from the ... time\n",
    "#cfg20200322T1741\n",
    "#Re-starting from epoch 20\n",
    "#Train mAP: 0.645\n",
    "#Test mAP: 0.378\n",
    "    \n",
    "#cfg20200322T1729\n",
    "#Re-starting from epoch 5\n",
    "#Train mAP: 0.334\n",
    "#Test mAP: 0.349\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#cfg_name = 'cfg20200325T2048'\n",
    "#model_epoch='0025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "1gwukJpbj4KM",
    "outputId": "20d6bc6d-588c-4a5d-a5a1-029849eb20f5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# detect opus_incertum in photos \n",
    "import os\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from matplotlib import pyplot\n",
    "from matplotlib.patches import Rectangle\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.model import mold_image\n",
    "from mrcnn.utils import Dataset\n",
    "\n",
    "\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "    # define the name of the configuration\n",
    "    NAME = construction_type+\"_cfg\"\n",
    "    # number of classes (background + opus_incertum)\n",
    "    NUM_CLASSES = 1 + 1\n",
    "    # simplify GPU config\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "# plot a number of photos with ground truth and predictions\n",
    "def plot_actual_vs_predicted(dataset, model, cfg, image_prediction_folder, n_images=10):\n",
    "    # load image and mask\n",
    "    for i in range(n_images):\n",
    "        # load the image and mask\n",
    "        image = dataset.load_image(i)\n",
    "        mask, _ = dataset.load_mask(i)\n",
    "        # convert pixel values (e.g. center)\n",
    "        scaled_image = mold_image(image, cfg)\n",
    "        # convert image into one sample\n",
    "        sample = expand_dims(scaled_image, 0)\n",
    "        # make prediction\n",
    "        yhat = model.detect(sample, verbose=0)[0]\n",
    "        # define subplot\n",
    "        #pyplot.subplot(n_images, 2, i*2+1)\n",
    "        # plot raw pixel data\n",
    "        pyplot.imshow(image)\n",
    "        pyplot.title('Actual')\n",
    "        # plot masks\n",
    "        for j in range(mask.shape[2]):\n",
    "            pyplot.imshow(mask[:, :, j], cmap='gray', alpha=0.3)\n",
    "        # get the context for drawing boxes\n",
    "        #pyplot.subplot(n_images, 2, i*2+2)\n",
    "        # plot raw pixel data\n",
    "        pyplot.savefig(image_prediction_folder+\"/\"+str(i)+\"_actual.jpg\")\n",
    "        pyplot.show()\n",
    "\n",
    "        pyplot.imshow(image)\n",
    "        pyplot.title('Predicted')\n",
    "        ax = pyplot.gca()\n",
    "        # plot each box\n",
    "        boxes_predicted = 0\n",
    "        for box in yhat['rois']:\n",
    "            # get coordinates\n",
    "            y1, x1, y2, x2 = box\n",
    "            # calculate width and height of the box\n",
    "            width, height = x2 - x1, y2 - y1\n",
    "            # create the shape\n",
    "            rect = Rectangle((x1, y1), width, height, fill=False, color='red')\n",
    "            # draw the box\n",
    "            ax.add_patch(rect)\n",
    "            boxes_predicted = boxes_predicted +1\n",
    "    # show the figure\n",
    "        pyplot.savefig(image_prediction_folder+\"/\"+str(i)+\"_predicted.jpg\")\n",
    "        pyplot.show()\n",
    "        print (\"boxes_predicted: %d\" % boxes_predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "id": "LGm4_JEej2lH",
    "outputId": "61705f88-b9e8-41c0-88c7-d7eb4dea5040",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 250\n",
      "Test: 30\n",
      "cfg20200628T1152\n",
      "Re-starting from epoch 16\n",
      "Train mAP: 0.691\n",
      "Test mAP: 0.795\n"
     ]
    }
   ],
   "source": [
    "# evaluate the mask rcnn model on the opus_incertum (or other construction type) dataset\n",
    "from os import listdir\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from numpy import expand_dims\n",
    "from numpy import mean\n",
    "from mrcnn.config import Config\n",
    "from mrcnn.model import MaskRCNN\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.utils import compute_ap\n",
    "from mrcnn.model import load_image_gt\n",
    "from mrcnn.model import mold_image\n",
    "\n",
    "\n",
    "\n",
    "# define the prediction configuration\n",
    "class PredictionConfig(Config):\n",
    "\t# define the name of the configuration\n",
    "\tNAME = construction_type+\"_cfg\" #\"opus_incertum_cfg\"\n",
    "\t# number of classes (background + opus_incertum)\n",
    "\tNUM_CLASSES = 1 + 1\n",
    "\t# simplify GPU config\n",
    "\tGPU_COUNT = 1\n",
    "\tIMAGES_PER_GPU = 1\n",
    "\n",
    "# calculate the mAP for a model on a given dataset\n",
    "def evaluate_model(dataset, model, cfg):\n",
    "\tAPs = list()\n",
    "\tfor image_id in dataset.image_ids:\n",
    "\t\t# load image, bounding boxes and masks for the image id\n",
    "\t\timage, image_meta, gt_class_id, gt_bbox, gt_mask = load_image_gt(dataset, cfg, image_id, use_mini_mask=False)\n",
    "\t\t# convert pixel values (e.g. center)\n",
    "\t\tscaled_image = mold_image(image, cfg)\n",
    "\t\t# convert image into one sample\n",
    "\t\tsample = expand_dims(scaled_image, 0)\n",
    "\t\t# make prediction\n",
    "\t\tyhat = model.detect(sample, verbose=0)\n",
    "\t\t# extract results for first sample\n",
    "\t\tr = yhat[0]\n",
    "\t\t# calculate statistics, including AP\n",
    "\t\tAP, _, _, _ = compute_ap(gt_bbox, gt_class_id, gt_mask, r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\n",
    "\t\t# store\n",
    "\t\tAPs.append(AP)\n",
    "\t# calculate the mean AP across all images\n",
    "\tmAP = mean(APs)\n",
    "\treturn mAP\n",
    "\n",
    "# load the train dataset\n",
    "train_set = ObjectDataset()\n",
    "train_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# load the test dataset\n",
    "test_set = ObjectDataset()\n",
    "test_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# create config\n",
    "pred_cfg = PredictionConfig()\n",
    "# define the model\n",
    "#cfg_name = 'cfg20200208T0930'\n",
    "#cfg_name = 'cfg20200301T1702'\n",
    "#cfg_name = ''\n",
    "#cfg_name = 'cfg20200317T2200'\n",
    "#cfg_name = 'cfg20200318T1120'\n",
    "# set this above\n",
    "print(cfg_name)\n",
    "model = MaskRCNN(mode='inference', model_dir='/storage/model/'+construction_type+'_'+cfg_name, config=pred_cfg)\n",
    "# load model weights\n",
    "model.load_weights('/storage/model/'+construction_type+'_'+cfg_name+'/mask_rcnn_'+construction_type+'_cfg_'+model_epoch+'.h5', by_name=True)\n",
    "\n",
    "# evaluate model on training dataset\n",
    "train_mAP = evaluate_model(train_set, model, pred_cfg)\n",
    "print(\"# Train mAP: %.3f\" % train_mAP)\n",
    "# evaluate model on test dataset\n",
    "test_mAP = evaluate_model(test_set, model, pred_cfg)\n",
    "print(\"# Test mAP: %.3f\" % test_mAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history1[\"val_loss\"])\n",
    "plt.ylabel('val_loss')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history2[\"val_loss\"])\n",
    "plt.ylabel('val_loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 596
    },
    "colab_type": "code",
    "id": "zKr2gYFOle6Z",
    "outputId": "426e813e-d899-475f-f97d-5d57eb8b98b0",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(cfg_name)\n",
    "# load the train dataset\n",
    "train_set = ObjectDataset()\n",
    "train_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=True)\n",
    "train_set.prepare()\n",
    "print('Train: %d' % len(train_set.image_ids))\n",
    "# load the test dataset\n",
    "test_set = ObjectDataset()\n",
    "test_set.load_dataset('/storage/images/charcoal_hearth_hill', is_train=False)\n",
    "test_set.prepare()\n",
    "print('Test: %d' % len(test_set.image_ids))\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='/storage/model/', config=cfg)\n",
    "# load model weights\n",
    "#cfg_name = 'cfg20200301T1702'\n",
    "#cfg_name = 'cfg20200317T2200'\n",
    "#cfg_name = 'cfg20200307T0901'\n",
    "#cfg_name = 'cfg20200317T2200'\n",
    "\n",
    "model_path = '/storage/model/'+construction_type+'_'+cfg_name+'/mask_rcnn_'+construction_type+'_cfg_'+model_epoch+'.h5'\n",
    "    \n",
    "model.load_weights(model_path, by_name=True)\n",
    "image_prediction_folder = '/home/student/data_5000_project/data/images/construction_types/processed/'+construction_type+'/predictions/'+cfg_name\n",
    "if not os.path.exists(image_prediction_folder):\n",
    "    os.mkdir(image_prediction_folder)\n",
    "\n",
    "# plot predictions for train dataset\n",
    "plot_actual_vs_predicted(train_set, model, cfg, image_prediction_folder,5)\n",
    "# plot predictions for test dataset\n",
    "plot_actual_vs_predicted(test_set, model, cfg, image_prediction_folder,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display image with masks and bounding boxes\n",
    "from os import listdir\n",
    "import skimage\n",
    "import random\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "import cv2\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='/storage/model/', config=cfg)\n",
    "# load model weights\n",
    "\n",
    "model_path = '/storage/model/'+construction_type+'_'+cfg_name+'/mask_rcnn_'+construction_type+'_cfg_'+model_epoch+'.h5'\n",
    "    \n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "image_for_prediction_folder = '/storage/images/charcoal_hearth_hill/images/jpgs/'\n",
    "\n",
    "image_prediction_folder = '/home/student/data_5000_project/data/images/construction_types/processed/'+construction_type+'/predictions/'+cfg_name+\"/unknown/\"\n",
    "if not os.path.exists(image_prediction_folder):\n",
    "    os.mkdir(image_prediction_folder)\n",
    "\n",
    "# Load a random image from the images folder\n",
    "file_names = next(os.walk(image_for_prediction_folder))[2]\n",
    "#print(file_names)\n",
    "class_names = [construction_type,construction_type]\n",
    "for cn in range(1,20):\n",
    "    \n",
    "    #image = skimage.io.imread(os.path.join(image_for_prediction_folder, random.choice(file_names)),False)\n",
    "    # load the image as RGB\n",
    "    # https://github.com/matterport/Mask_RCNN/issues/1435\n",
    "    image = cv2.imread(os.path.join(image_for_prediction_folder, random.choice(file_names)))\n",
    "    # Run detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    image2= display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['520104.jpg', '390714.jpg', '581205.jpg', '581303.jpg', '391605.jpg', '390624.jpg', '410012.jpg', '550006.jpg', '390010.jpg', '390624.jpg', '461004.jpg', '581109.jpg', '581614.jpg', '410010.jpg', '391707.jpg', '720505.jpg', '551209.jpg', '550308.jpg', '580804.jpg', '551010.jpg', '580309.jpg', '410120.jpg', '430804.jpg', '411120.jpg', '410204.jpg', '720302.jpg', '720405.jpg', '410905.jpg', '430411.jpg', '551204.jpg', '550904.jpg', '391117.jpg', '390924.jpg', '410201.jpg', '391106.jpg', '550206.jpg', '551208.jpg', '461101.jpg', '410112.jpg', '410715.jpg', '720210.jpg', '720407.jpg', '390704.jpg', '411110.jpg', '580612.jpg', '550803.jpg', '461314.jpg', '390115.jpg', '390802.jpg', '410305.jpg', '581306.jpg', '460915.jpg', '720003.jpg', '430203.jpg', '410305.jpg', '410210.jpg', '580712.jpg', '580606.jpg', '460506.jpg', '581118.jpg', '430711.jpg', '580109.jpg', '580707.jpg', '390516.jpg', '550204.jpg', '520102.jpg', '391403.jpg', '430308.jpg', '581905.jpg', '460809.jpg', '580807.jpg', '720410.jpg', '430901.jpg', '390523.jpg', '550703.jpg', '581118.jpg', '581401.jpg', '430404.jpg', '581103.jpg', '461209.jpg', '461111.jpg', '411113.jpg', '460605.jpg', '460413.jpg', '460706.jpg', '460810.jpg', '461015.jpg', '390705.jpg', '582006.jpg', '520607.jpg', '720208.jpg', '410905.jpg', '391611.jpg', '430902.jpg', '391604.jpg', '390306.jpg', '461109.jpg', '581801.jpg', '550704.jpg', '390805.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Run only once\n",
    "cause.errir\n",
    "image_for_prediction_folder = '/storage/images/charcoal_hearth_hill/images/jpgs/'\n",
    "file_names = next(os.walk(image_for_prediction_folder))[2]\n",
    "#print(file_names)\n",
    "test_file_names=[]\n",
    "for cn in range(0,100):\n",
    "    test_file_names.append(random.choice(file_names))\n",
    "\n",
    "print(test_file_names)\n",
    "\n",
    "import pickle\n",
    "with open('rcnn_100_random_images_charcoal_hearth_hill.pkl', 'wb') as f:\n",
    "    #pickle.dump(test_file_names, f)\n",
    "\n",
    "    \n",
    "\n",
    "with open('rcnn_100_random_images_charcoal_hearth_hill.pkl', 'rb') as f:\n",
    "    test_file_names = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def write_annot(obj_type, obj_annots_dir, obj_f_num, org_f_name, org_f_path,org_f_width,org_f_height,org_f_depth, refPts, scores):\n",
    "    # With credit to: \n",
    "    # https://www.geeksforgeeks.org/reading-writing-text-files-python/\n",
    "    annot_file_path = obj_annots_dir+obj_f_num+'.xml'\n",
    "    annot_file = open(annot_file_path,\"w\") \n",
    "\n",
    "    annot_file.write(\"<annotation>\\n\") \n",
    "    annot_file.write(\"\t<folder>\"+obj_type+\"</folder>\\n\") \n",
    "    annot_file.write(\"\t<filename>\"+org_f_name+\"</filename>\\n\") \n",
    "    annot_file.write(\"\t<path>\"+org_f_path+\"</path>\\n\") \n",
    "    annot_file.write(\"\t<source>\\n\") \n",
    "    annot_file.write(\"\t\t<database>Muhlenberg_charcoal_hearths</database>\\n\") \n",
    "    annot_file.write(\"\t</source>\\n\") \n",
    "    annot_file.write(\"\t<size>\\n\") \n",
    "    annot_file.write(\"\t\t<width>\"+str(org_f_width)+\"</width>\\n\") \n",
    "    annot_file.write(\"\t\t<height>\"+str(org_f_height)+\"</height>\\n\") \n",
    "    annot_file.write(\"\t\t<depth>\"+str(org_f_depth)+\"</depth>\\n\") \n",
    "    annot_file.write(\"\t</size>\\n\")\n",
    "#    annot_file.write(\"\t<!-- <object_present>0 = the object such as opus incertum is not present in the image. 1 = it is -->\\n\")\n",
    "#    annot_file.write(\"\t<object_present>0</object_present>\\n\")    \n",
    "    for ocn in range(0,len(refPts)):\n",
    "        refPt = refPts[ocn]\n",
    "        refPtMin = refPt[0]\n",
    "        refPtMax = refPt[1]\n",
    "        annot_file.write(\"\t<object>\\n\") \n",
    "        annot_file.write(\"\t\t<name>\"+obj_type+\"</name>\\n\") \n",
    "        annot_file.write(\"\t\t<number>\"+str(ocn)+\"</number>\\n\") \n",
    "        annot_file.write(\"\t\t<score>\"+str(scores[ocn])+\"</score>\\n\")\n",
    "        annot_file.write(\"\t\t<correct>0</correct>\\n\")\n",
    "        annot_file.write(\"\t\t<bndbox>\\n\") \n",
    "        annot_file.write(\"\t\t\t<xmin>\"+str(refPtMin[0])+\"</xmin>\\n\") \n",
    "        annot_file.write(\"\t\t\t<ymin>\"+str(refPtMin[1])+\"</ymin>\\n\") \n",
    "        annot_file.write(\"\t\t\t<xmax>\"+str(refPtMax[0])+\"</xmax>\\n\") \n",
    "        annot_file.write(\"\t\t\t<ymax>\"+str(refPtMax[1])+\"</ymax>\\n\") \n",
    "        annot_file.write(\"\t\t</bndbox>\\n\") \n",
    "        annot_file.write(\"\t</object>\\n\") \n",
    "    annot_file.write(\"</annotation>\\n\") \n",
    "    annot_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"cfg_name:\",cfg_name)\n",
    "import pickle\n",
    "import os\n",
    "with open('rcnn_100_random_images_charcoal_hearth_hill.pkl', 'rb') as f:\n",
    "    test_file_names = pickle.load(f)\n",
    "\n",
    "#set this above\n",
    "#cfg_name = 'cfg20200307T0901'    \n",
    "# display image with masks and bounding boxes\n",
    "from os import listdir\n",
    "import skimage\n",
    "import random\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='/storage/model/', config=cfg)\n",
    "# load model weights\n",
    "\n",
    "model_path = '/storage/model/'+construction_type+'_'+cfg_name+'/mask_rcnn_'+construction_type+'_cfg_'+model_epoch+'.h5'\n",
    "image_for_prediction_folder = '/storage/images/charcoal_hearth_hill/images/jpgs/'    \n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "image_prediction_folder = '/home/student/data_5000_project/data/images/construction_types/processed/'+construction_type+'/predictions/'+cfg_name+\"/unknown/\"\n",
    "if not os.path.exists(image_prediction_folder):\n",
    "    os.mkdir(image_prediction_folder)\n",
    "\n",
    "#Store the results in XML    \n",
    "class_names = [construction_type,construction_type,]\n",
    "for cn in range(0,100):\n",
    "    image = cv2.imread(os.path.join(image_for_prediction_folder, test_file_names[cn]))\n",
    "    #image = skimage.io.imread(os.path.join(image_for_prediction_folder, test_file_names[cn]))\n",
    "    #print(\"shape:\", image.shape)\n",
    "    # Run detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    #print(r['rois'], class_names, r['scores'])\n",
    "    #print(r['rois'][1],r['rois'][1][0],r['rois'][1][1],r['rois'][1][2],r['rois'][1][3])\n",
    "    image2= display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "                            class_names, r['scores'])\n",
    "    obj_f_num = \"00000\"+str(cn)\n",
    "    obj_f_num = obj_f_num[-5:]\n",
    "    refPts = []\n",
    "    for rcn in range(0,len(r['rois'])):\n",
    "        refPt = []\n",
    "        refPtM = []\n",
    "        refPtM.append(r['rois'][rcn][1])\n",
    "        refPtM.append(r['rois'][rcn][0])\n",
    "        refPt.append(refPtM)\n",
    "        refPtM = []\n",
    "        refPtM.append(r['rois'][rcn][3])\n",
    "        refPtM.append(r['rois'][rcn][2])\n",
    "        refPt.append(refPtM)\n",
    "        refPts.append(refPt)\n",
    "        print(refPts)\n",
    "    write_annot(class_names[0], image_prediction_folder, obj_f_num, test_file_names[cn], image_for_prediction_folder,image.shape[1],image.shape[0],image.shape[2], refPts,r['scores'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Predict it for all the images\n",
    "print(\"cfg_name:\",cfg_name)\n",
    "\n",
    "#For all of the jpegs, run prediction\n",
    "\n",
    "#images_dir\n",
    "#use this for all the images\n",
    "#images_dir = '/storage/images/charcoal_hearth_hill/images/jpgs/'\n",
    "#use this to rerun for all the training images (improve the training data with a second pass)\n",
    "images_dir = '/storage/images/charcoal_hearth_hill/images_training/'\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "#set this above\n",
    "#cfg_name = 'cfg20200307T0901'    \n",
    "\n",
    "from os import listdir\n",
    "import skimage\n",
    "import cv2\n",
    "from xml.etree import ElementTree\n",
    "from numpy import zeros\n",
    "from numpy import asarray\n",
    "from mrcnn.utils import Dataset\n",
    "from mrcnn.visualize import display_instances\n",
    "from mrcnn.utils import extract_bboxes\n",
    "\n",
    "# create config\n",
    "cfg = PredictionConfig()\n",
    "# define the model\n",
    "model = MaskRCNN(mode='inference', model_dir='/storage/model/', config=cfg)\n",
    "# load model weights\n",
    "\n",
    "model_path = '/storage/model/'+construction_type+'_'+cfg_name+'/mask_rcnn_'+construction_type+'_cfg_'+model_epoch+'.h5'\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "image_prediction_folder = '/storage/images/'+construction_type+'/predictions/'+cfg_name\n",
    "image_for_prediction_folder = '/storage/images/charcoal_hearth_hill/images/jpgs/'  \n",
    "if not os.path.exists(image_prediction_folder):\n",
    "    os.mkdir(image_prediction_folder)\n",
    "image_prediction_folder = image_prediction_folder+'/unknown/'\n",
    "if not os.path.exists(image_prediction_folder):\n",
    "    os.mkdir(image_prediction_folder)\n",
    "\n",
    "    \n",
    "    \n",
    "#Store the results in XML    \n",
    "class_names = [construction_type,construction_type,]\n",
    "\n",
    "\n",
    "# find all images\n",
    "for filename in listdir(images_dir):\n",
    "    # extract image id\n",
    "    image_id = filename[:-4]\n",
    "    img_path = images_dir + filename\n",
    "    #ann_path = annotations_dir + image_id + '.xml'\n",
    "    #print(image_id,img_path,ann_path)\n",
    "    print(image_id,img_path)\n",
    "    \n",
    "    image = cv2.imread(img_path)\n",
    "    #image = skimage.io.imread(os.path.join(image_for_prediction_folder, test_file_names[cn]))\n",
    "    #print(\"shape:\", image.shape)\n",
    "    # Run detection\n",
    "    results = model.detect([image], verbose=1)\n",
    "    # Visualize results\n",
    "    r = results[0]\n",
    "    #print(r['rois'], class_names, r['scores'])\n",
    "    #print(r['rois'][1],r['rois'][1][0],r['rois'][1][1],r['rois'][1][2],r['rois'][1][3])\n",
    "    #image2= display_instances(image, r['rois'], r['masks'], r['class_ids'], \n",
    "    #class_names, r['scores'])\n",
    "    obj_f_num = image_id\n",
    "    refPts = []\n",
    "    for rcn in range(0,len(r['rois'])):\n",
    "        refPt = []\n",
    "        refPtM = []\n",
    "        refPtM.append(r['rois'][rcn][1])\n",
    "        refPtM.append(r['rois'][rcn][0])\n",
    "        refPt.append(refPtM)\n",
    "        refPtM = []\n",
    "        refPtM.append(r['rois'][rcn][3])\n",
    "        refPtM.append(r['rois'][rcn][2])\n",
    "        refPt.append(refPtM)\n",
    "        refPts.append(refPt)\n",
    "        #print(refPts)\n",
    "    write_annot(class_names[0], image_prediction_folder, obj_f_num, filename, image_for_prediction_folder,image.shape[1],image.shape[0],image.shape[2], refPts,r['scores'])\n",
    "print(\"The results are in: \"+image_prediction_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "rcnn-pompeii.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
