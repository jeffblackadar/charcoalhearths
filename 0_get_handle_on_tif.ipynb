{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tif = 'BlueMtHearthforShawnJeff.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pcjericks.github.io/py-gdalogr-cookbook/raster_layers.html#clip-a-geotiff-with-shapefile\n",
    "import gdal\n",
    "\n",
    "# open dataset\n",
    "ds = gdal.Open('BlueMtHearthforShawnJeff.tif')\n",
    "cols = ds.RasterXSize\n",
    "rows = ds.RasterYSize\n",
    "bands = ds.RasterCount\n",
    "print(cols, rows, bands)\n",
    "ds = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'GetLayer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-511e3b33ab74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataSource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mogr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdaShapefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdaLayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataSource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetLayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mlayerDefinition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdaLayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetLayerDefn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'GetLayer'"
     ]
    }
   ],
   "source": [
    "from osgeo import ogr\n",
    "\n",
    "daShapefile = r\"CharcoalHearthsforJeffShawn.shp\"\n",
    "\n",
    "dataSource = ogr.Open(daShapefile)\n",
    "daLayer = dataSource.GetLayer(0)\n",
    "layerDefinition = daLayer.GetLayerDefn()\n",
    "\n",
    "\n",
    "for i in range(layerDefinition.GetFieldCount()):\n",
    "    print(layerDefinition.GetFieldDefn(i).GetName())\n",
    "print(\"Name  -  Type  Width  Precision\")\n",
    "for i in range(layerDefinition.GetFieldCount()):\n",
    "    fieldName =  layerDefinition.GetFieldDefn(i).GetName()\n",
    "    fieldTypeCode = layerDefinition.GetFieldDefn(i).GetType()\n",
    "    fieldType = layerDefinition.GetFieldDefn(i).GetFieldTypeName(fieldTypeCode)\n",
    "    fieldWidth = layerDefinition.GetFieldDefn(i).GetWidth()\n",
    "    GetPrecision = layerDefinition.GetFieldDefn(i).GetPrecision()\n",
    "\n",
    "    print(fieldName + \" - \" + fieldType+ \" \" + str(fieldWidth) + \" \" + str(GetPrecision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thanks\n",
    "#https://podaac.jpl.nasa.gov/forum/viewtopic.php?f=5&t=657\n",
    "    \n",
    "import os\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "from osgeo import osr\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "#Plot setup\n",
    "fig= plt.figure(figsize=(10,8))\n",
    "\n",
    "ax = plt.subplot(111,aspect = 'equal')\n",
    "plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, top=0.9, wspace=0, hspace=0)\n",
    "\n",
    "#Map setup\n",
    "map = Basemap(resolution='f', projection='cyl', llcrnrlon=-74.72, llcrnrlat=39.71, urcrnrlon=-80.53, urcrnrlat=41.18)\n",
    "\n",
    "parallels = np.arange(-50,50,1.)\n",
    "meridians = np.arange(0,360,1)\n",
    "\n",
    "map.drawparallels(parallels,labels=[1,0,0,0],color='w', fontsize=10, fontweight='bold')\n",
    "meri = map.drawmeridians(meridians,labels=[0,0,0,1],color='w', fontsize=10, fontweight='bold')\n",
    "\n",
    "#Load colormap and setup elevation contour levels\n",
    "cmap=plt.get_cmap(\"jet\")\n",
    "clevs = np.linspace(0, 3000, 21)\n",
    "\n",
    "# Load GeoTiff data\n",
    "raster = my_tif\n",
    "ds = gdal.Open(raster)\n",
    "\n",
    "#Get the dimentions of column and row\n",
    "nc   = ds.RasterXSize\n",
    "nr   = ds.RasterYSize\n",
    "\n",
    "#Read elevation data\n",
    "data = ds.ReadAsArray()\n",
    "\n",
    "#Get Longitude and Latitude info\n",
    "geotransform = ds.GetGeoTransform()\n",
    "xOrigin      = geotransform[0]\n",
    "yOrigin      = geotransform[3]\n",
    "pixelWidth   = geotransform[1]\n",
    "pixelHeight  = geotransform[5]\n",
    "\n",
    "#Generate Longitude and Latitude array\n",
    "lons = xOrigin + np.arange(0, nc)*pixelWidth\n",
    "lats = yOrigin + np.arange(0, nr)*pixelHeight\n",
    "\n",
    "#Contour plot\n",
    "x, y = map(*np.meshgrid(lons, lats))\n",
    "\n",
    "cs=map.contourf(x, y, data, clevs, cmap=cmap)\n",
    "\n",
    "map.drawparallels(parallels,labels=[1,0,0,0],color='k', fontsize=10, fontweight='bold')\n",
    "meri = map.drawmeridians(meridians,labels=[0,0,0,1],color='k', fontsize=10, fontweight='bold')\n",
    "\n",
    "cb = map.colorbar(cs, 'bottom', size='5%', pad='10%')\n",
    "\n",
    "cb.set_label('Elevation (m)', fontsize=12, fontweight='bold')\n",
    "cb.ax.tick_params(labelsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import georaster\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "\n",
    "m = Basemap(projection='lcc', lon_0=67.5, lat_0=-68.5, \\\n",
    "            height=950000, width=580000, resolution='h')\n",
    "\n",
    "m.drawcoastlines()\n",
    "m.fillcontinents(color='beige')\n",
    "\n",
    "image = georaster.SingleBandRaster( my_tif, latlon=False)\n",
    "plt.imshow(image.r, extent=image.extent, zorder=10, alpha=0.6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from mpl_toolkits.basemap import Basemap\n",
    "from mpl_toolkits.basemap import shiftgrid\n",
    "import matplotlib.pyplot as plt\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "\n",
    "-80.53, 39.71, -74.72, 41.18\n",
    "\n",
    "map = Basemap(resolution='f', projection='cyl', llcrnrlon=-74.72, llcrnrlat=39.71, urcrnrlon=-80.53, urcrnrlat=41.18)\n",
    "#map = Basemap(projection='tmerc', \n",
    "#              lat_0=0, lon_0=3,\n",
    "#              llcrnrlon=74, \n",
    "#              llcrnrlat=39, \n",
    "#              urcrnrlon=81, \n",
    "#              urcrnrlat=43)\n",
    "\n",
    "ds = gdal.Open(my_tif)\n",
    "elevation = ds.ReadAsArray()\n",
    "print(elevation)\n",
    "#map.imshow(plt.imread('../sample_files/orthophoto.jpg'))\n",
    "\n",
    "map.imshow(elevation, cmap = plt.get_cmap('Blues'), alpha = 0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from affine import Affine\n",
    "da = xr.open_rasterio(my_tif)\n",
    "print (da)\n",
    "transform = Affine.from_gdal(*da.attrs['transform']) # this is important to retain the geographic attributes from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(da.variable.data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(da.variable.data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/the-barometer/read-and-plot-geotiff-in-python-xarray-cartopy-fd48faf1c503\n",
    "# Imports\n",
    "import xarray as xr\n",
    "from affine import Affine\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "# Read the data\n",
    "da = xr.open_rasterio(my_tif)\n",
    "transform = Affine.from_gdal(*da.attrs['transform'])\n",
    "\n",
    "print(da.attrs['transform'])\n",
    "# Define extents\n",
    "#llcrnrlon=-74.72, llcrnrlat=39.71, urcrnrlon=-80.53, urcrnrlat=41.18\n",
    "lat_min = 39.71\n",
    "lat_max = 41.18\n",
    "lon_min = 74.72\n",
    "lon_max = 80.53\n",
    "\n",
    "# Define the projection\n",
    "crs=ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = plt.figure(figsize=(16,8))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(da.variable.data[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create meshgrid from geotiff\n",
    "nx, ny = da.sizes['x'], da.sizes['y']\n",
    "x, y = np.meshgrid(np.arange(nx), np.arange(ny)) * transform\n",
    "print(da.sizes)\n",
    "print(transform)\n",
    "# Plot!\n",
    "fig = plt.figure(figsize=(32,8))\n",
    "#fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection=crs)\n",
    "#ax.coastlines(resolution='10m', alpha=0.1)\n",
    "ax.contourf(x, y, da.variable.data[0], cmap='Greys')\n",
    "ax.set_extent([lon_min, lon_max, lat_min, lat_max])\n",
    "\n",
    "# Grid and Labels\n",
    "gl = ax.gridlines(crs=crs, draw_labels=True, alpha=0.5)\n",
    "gl.xlabels_top = None\n",
    "gl.ylabels_right = None\n",
    "xgrid = np.arange(lon_min-0.5, lon_max+.5, 1.)\n",
    "ygrid = np.arange(lat_min, lat_max+1, 1.)\n",
    "gl.xlocator = mticker.FixedLocator(xgrid.tolist())\n",
    "gl.ylocator = mticker.FixedLocator(ygrid.tolist())\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 14, 'color': 'black'}\n",
    "gl.ylabel_style = {'size': 14, 'color': 'black'}\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://ocefpaf.github.io/python4oceanographers/blog/2015/03/02/geotiff/\n",
    "from osgeo import gdal, osr\n",
    "\n",
    "gdal.UseExceptions()\n",
    "\n",
    "\n",
    "fname = my_tif\n",
    "\n",
    "ds = gdal.Open(fname)\n",
    "data = ds.ReadAsArray()\n",
    "gt = ds.GetGeoTransform()\n",
    "proj = ds.GetProjection()\n",
    "\n",
    "inproj = osr.SpatialReference()\n",
    "inproj.ImportFromWkt(proj)\n",
    "\n",
    "print(inproj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "\n",
    "\n",
    "projcs = inproj.GetAuthorityCode('PROJCS')\n",
    "projection = ccrs.epsg(projcs)\n",
    "print(projection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "subplot_kw = dict(projection=projection)\n",
    "fig, ax = plt.subplots(figsize=(9, 9), subplot_kw=subplot_kw)\n",
    "\n",
    "extent = (gt[0], gt[0] + ds.RasterXSize * gt[1],\n",
    "          gt[3] + ds.RasterYSize * gt[5], gt[3])\n",
    "\n",
    "img = ax.imshow(data[:3, :].transpose((1,0)), extent=extent, origin='upper')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[3,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Thanksfrom osgeo import gdal\n",
    "\n",
    "filepath = r\"LandsatData/LC81910182016153LGN00_sr_band4.tif\"\n",
    "\n",
    "# Open the file:\n",
    "raster = gdal.Open(filepath)\n",
    "\n",
    "# Check type of the variable 'raster'\n",
    "type(raster)\n",
    "#https://gis.stackexchange.com/questions/182489/find-rectangle-around-point-with-python\n",
    "from math import sqrt,atan,pi\n",
    "import pyproj\n",
    "geod = pyproj.Geod(ellps='WGS84')\n",
    "\n",
    "width = 10000. # m\n",
    "height = 20000. # m\n",
    "rect_diag = sqrt( width**2 + height**2 )\n",
    "\n",
    "center_lon = -78.6389\n",
    "center_lat = 35.7806\n",
    "\n",
    "azimuth1 = atan(width/height)\n",
    "azimuth2 = atan(-width/height)\n",
    "azimuth3 = atan(width/height)+pi # first point + 180 degrees\n",
    "azimuth4 = atan(-width/height)+pi # second point + 180 degrees\n",
    "\n",
    "pt1_lon, pt1_lat, _ = geod.fwd(center_lon, center_lat, azimuth1*180/pi, rect_diag)\n",
    "pt2_lon, pt2_lat, _ = geod.fwd(center_lon, center_lat, azimuth2*180/pi, rect_diag)\n",
    "pt3_lon, pt3_lat, _ = geod.fwd(center_lon, center_lat, azimuth3*180/pi, rect_diag)\n",
    "pt4_lon, pt4_lat, _ = geod.fwd(center_lon, center_lat, azimuth4*180/pi, rect_diag)\n",
    "\n",
    "wkt_point = 'POINT (%.6f %.6f)' % (center_lon, center_lat)\n",
    "wkt_poly = 'POLYGON (( %.6f %.6f, %.6f %.6f, %.6f %.6f, %.6f %.6f, %.6f %.6f ))' % (pt1_lon, pt1_lat, pt2_lon, pt2_lat, pt3_lon, pt3_lat, pt4_lon, pt4_lat, pt1_lon, pt1_lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://automating-gis-processes.github.io/2016/Lesson7-read-raster.html\n",
    "from osgeo import gdal\n",
    "\n",
    "filepath = my_tif\n",
    "\n",
    "# Open the file:\n",
    "raster = gdal.Open(filepath)\n",
    "\n",
    "# Check type of the variable 'raster'\n",
    "type(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Projection\n",
    "raster.GetProjection()\n",
    "\n",
    "# Dimensions\n",
    "raster.RasterXSize\n",
    "raster.RasterYSize\n",
    "\n",
    "# Number of bands\n",
    "raster.RasterCount\n",
    "\n",
    "# Metadata for the raster dataset\n",
    "raster.GetMetadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the raster band as separate variable\n",
    "band = raster.GetRasterBand(1)\n",
    "\n",
    "# Check type of the variable 'band'\n",
    "type(band)\n",
    "\n",
    "# Data type of the values\n",
    "gdal.GetDataTypeName(band.DataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute statistics if needed\n",
    "if band.GetMinimum() is None or band.GetMaximum()is None:\n",
    "    band.ComputeStatistics(0)\n",
    "    print(\"Statistics computed.\")\n",
    "\n",
    "# Fetch metadata for the band\n",
    "band.GetMetadata()\n",
    "\n",
    "# Print only selected metadata:\n",
    "print (\"[ NO DATA VALUE ] = \", band.GetNoDataValue()) # none\n",
    "print (\"[ MIN ] = \", band.GetMinimum())\n",
    "print (\"[ MAX ] = \", band.GetMaximum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read raster data as numeric array from GDAL Dataset\n",
    "rasterArray = raster.ReadAsArray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check the datatype of variables\n",
    "type(rasterArray)\n",
    "type(raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal_array\n",
    "\n",
    "# Read raster data as numeric array from file\n",
    "rasterArray = gdal_array.LoadFile(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rasterArray.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get nodata value from the GDAL band object\n",
    "nodata = band.GetNoDataValue()\n",
    "\n",
    "#Create a masked array for making calculations without nodata values\n",
    "rasterArray = np.ma.masked_equal(rasterArray, nodata)\n",
    "type(rasterArray)\n",
    "\n",
    "# Check again array statistics\n",
    "rasterArray.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "In [1]: import geopandas as gpd\n",
    "\n",
    "# Set filepath (fix path relative to yours)\n",
    "In [2]: fp = \"CharcoalHearthsforJeffShawn.shp\"\n",
    "\n",
    "# Read file using gpd.read_file()\n",
    "In [3]: data = gpd.read_file(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [4]: type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [5]: data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [6]: data.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [7]: data.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In [8]: data['geometry'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "# Create a Polygon\n",
    "lat_min = 39.71\n",
    "lat_max = 41.18\n",
    "lon_min = -74.72\n",
    "lon_max = -80.53\n",
    "\n",
    "(-75.71725268214374, 40.764397146754874, 0.0)\n",
    "(-75.71695514265, 40.774222278709765, 0.0)\n",
    "(-75.70005461271417, 40.76409483152501, 0.0)\n",
    "(-75.69975455768758, 40.773919920041344, 0.0)\n",
    "\n",
    "\n",
    "\n",
    "coords = [(lon_min, lat_min), (lon_max, lat_min), (lon_max, lat_max), (lon_min, lat_max)]\n",
    "poly = Polygon(coords)\n",
    "\n",
    "selection = data[0:]\n",
    "for index, row in selection.iterrows():\n",
    "    pt = row['geometry']\n",
    "    print(pt, pt.within(poly))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "ds = gdal.Open(my_tif)\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "gt = ds.GetGeoTransform()\n",
    "minx = gt[0]\n",
    "miny = gt[3] + width*gt[4] + height*gt[5] \n",
    "maxx = gt[0] + width*gt[1] + height*gt[2]\n",
    "maxy = gt[3] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(minx,maxx,miny,maxy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wgs84_to_modissinu ( lon, lat ):\n",
    "    wgs84 = osr.SpatialReference( )\n",
    "    wgs84.ImportFromEPSG( 4326 )\n",
    "    modis_sinu = osr.SpatialReference() \n",
    "    modis_sinu.ImportFromProj4 ( \"+proj=sinu +lon_0=0 +x_0=0 +y_0=0 +a=6371007.181 +b=6371007.181 +units=m +no_defs\" )\n",
    "    tx = osr.CoordinateTransformation(wgs84, modis_sinu)\n",
    "    modis_x, modis_y, modis_z = tx.TransformPoint ( lon, lat )\n",
    "    return modis_x, modis_y, modis_z \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "***** Move it down!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This is being re-written above \n",
    "\n",
    "\n",
    "# https://gis.stackexchange.com/questions/129847/obtain-coordinates-and-corresponding-pixel-values-from-geotiff-using-python-gdal\n",
    "#    #open raster layer\n",
    "src_ds=gdal.Open(my_tif) \n",
    "gt=src_ds.GetGeoTransform()\n",
    "\n",
    "print(\"gt\",gt)\n",
    "rb=src_ds.GetRasterBand(1)\n",
    "\n",
    "#Get the dimentions of column and row\n",
    "nc   = src_ds.RasterXSize\n",
    "nr   = src_ds.RasterYSize\n",
    "\n",
    "xOrigin      = gt[0]\n",
    "yOrigin      = gt[3]\n",
    "pixelWidth   = gt[1]\n",
    "pixelHeight  = gt[5]\n",
    "\n",
    "#Generate Longitude and Latitude array\n",
    "lons = xOrigin + np.arange(0, nc)*pixelWidth\n",
    "lats = yOrigin + np.arange(0, nr)*pixelHeight\n",
    "\n",
    "\n",
    "gdal.UseExceptions() #so it doesn't print to screen everytime point is outside grid\n",
    "print(src_ds)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the source projection, WGS84 lat/lon. \n",
    "nad83_1 = osr.SpatialReference( ) # Define a SpatialReference object\n",
    "nad83_1.ImportFromEPSG(7019) # And set it to WGS84 using the EPSG code\n",
    "\n",
    "# Now for the target projection, MODIS sinusoidal\n",
    "modis_sinu = osr.SpatialReference() # define the SpatialReference object\n",
    "# In this case, we get the projection from a Proj4 string\n",
    "modis_sinu.ImportFromProj4 (\"+proj=sinu +R=6371007.181 +nadgrids=@null +wktext\")\n",
    "\n",
    "# Now, we define a coordinate transformtion object, *from* wgs84 *to* modis_sinu\n",
    "tx = osr.CoordinateTransformation( nad83_1, modis_sinu )\n",
    "\n",
    "#lyr=src_ds.GetLayer(0)\n",
    "\n",
    "#for feat in lyr:\n",
    "#    geom=feat.GetGeometryRef()\n",
    "#    mx=geom.Centroid().GetX()\n",
    "#    my=geom.Centroid().GetY()\n",
    "\n",
    "#    px = int((mx - gt[0]) / gt[1]) #x pixel\n",
    "#    py = int((my - gt[3]) / gt[5]) #y pixel\n",
    "        \n",
    "        \n",
    "# Make annotation file for the jpeg from polygons\n",
    "for index, row in hearth_data_poly.iterrows():\n",
    "    poly = row['geometry']\n",
    "    #print(row, row['id'])\n",
    "    print(poly)\n",
    "    \n",
    "    boundary = poly.bounds\n",
    "    print(boundary[0])\n",
    "    print(boundary[1])\n",
    "    print(boundary[2])\n",
    "    print(boundary[3])\n",
    "    pt1_coords = [(boundary[0], boundary[1])]\n",
    "    pt2_coords = [(boundary[2], boundary[3])]\n",
    "    pt1 = Point(pt1_coords)\n",
    "    print(pt1)\n",
    "    lon = boundary[0]\n",
    "    lat = boundary[1]\n",
    "    #lon = float ( lon )\n",
    "    #lat = float ( lat )\n",
    "    #lon = -4.025\n",
    "    #lat= 56.59\n",
    "    # Actually do the transformation using the TransformPoint method\n",
    "    print(\"lon,lat\",lon, lat)\n",
    "    modis_x, modis_y,modis_z = wgs84_to_modissinu ( lon,lat )    \n",
    "    \n",
    "    print(\"origin\",xOrigin, yOrigin)\n",
    "    print(\"modis\",modis_x, modis_y)\n",
    "    #https://jgomezdans.github.io/gdal_notes/first_steps.html\n",
    "    pixel_x = (modis_x - xOrigin)*pixelWidth    \n",
    "    \n",
    "    # The difference in distance between the UL corner (geot[0] \\\n",
    "    # and point of interest. Scaled by geot[1] to get pixel number\n",
    "    pixel_y = (modis_y - yOrigin)*pixelHeight\n",
    "    #In [55]: pixel_x\n",
    "    #Out[55]: 2132.115490094644 # A real number, not an integer!\n",
    "    print(\"pixels\",pixel_x, pixel_y)\n",
    "    #In [59]: pixel_y = (5936117.4 - geot[3])/(geot[5]) # Like for pixel_x, \\\n",
    "        #but in vertical direction. Note the different elements of geot \\\n",
    "        #being used\n",
    "    \n",
    "    \n",
    "    #for i in range(0, poly.GetPointCount()):\n",
    "    # GetPoint returns a tuple not a Geometry\n",
    "#        pt = poly.GetPoint(i)\n",
    " #       print (\"%i). POINT (%d %d)\" %(i, pt[0], pt[1]))\n",
    "    #select only points inside the bounds of the geotiff AND are confirmed to be hearths\n",
    "    #if(pt.within(poly)==True):\n",
    "#        if(row['Confirmed']=='hearth'):\n",
    " #           print(pt, pt.within(poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save a shapefile with just the points inside the geotiff and confirmed hearths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-80.03467167100652, 41.21431609733511, 0.0)\n",
      "(-80.04043856209015, 41.37894262196131, 0.0)\n",
      "(-79.8218581677315, 41.38308947736159, 0.0)\n",
      "(-79.81664118024932, 41.218452607697024, 0.0)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import geopandas as gpd\n",
    "\n",
    "# Set filepath (fix path relative to yours)\n",
    "fp = \"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Shapefiles_5-20-2020/Charcoal-Hearths.shp\"\n",
    "\n",
    "# Read file using gpd.read_file()\n",
    "data = gpd.read_file(fp)\n",
    "    \n",
    "\n",
    "#https://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "from osgeo import osr, gdal\n",
    "\n",
    "# get the existing coordinate system\n",
    "ds = gdal.Open(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/39/39_jeff_slope.tif\")\n",
    "\n",
    "old_cs= osr.SpatialReference()\n",
    "\n",
    "old_cs.ImportFromWkt(ds.GetProjectionRef())\n",
    "\n",
    "# create the new coordinate system\n",
    "nad83_wkt = \"\"\"\n",
    "    GEOGCS[\"NAD83\",\n",
    "        DATUM[\"North_American_Datum_1983\",\n",
    "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
    "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
    "            TOWGS84[0,0,0,0,0,0,0],\n",
    "            AUTHORITY[\"EPSG\",\"6269\"]],\n",
    "        PRIMEM[\"Greenwich\",0,\n",
    "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "        UNIT[\"degree\",0.0174532925199433,\n",
    "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "        AUTHORITY[\"EPSG\",\"4269\"]]\"\"\"\n",
    "\n",
    "\n",
    "#GEOGCS[\"WGS 84\",\n",
    "#    DATUM[\"WGS_1984\",\n",
    "#        SPHEROID[\"WGS 84\",6378137,298.257223563,\n",
    "#            AUTHORITY[\"EPSG\",\"7030\"]],\n",
    "#        AUTHORITY[\"EPSG\",\"6326\"]],\n",
    "#    PRIMEM[\"Greenwich\",0,\n",
    "#        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "#    UNIT[\"degree\",0.01745329251994328,\n",
    "#        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "#    AUTHORITY[\"EPSG\",\"4326\"]]\"\"\"\n",
    "\n",
    "\n",
    "new_cs = osr.SpatialReference()\n",
    "#new_cs .ImportFromWkt(wgs84_wkt)\n",
    "new_cs .ImportFromWkt(nad83_wkt)\n",
    "\n",
    "# create a transform object to convert between coordinate systems\n",
    "transform = osr.CoordinateTransformation(old_cs,new_cs) \n",
    "\n",
    "#get the point to transform, pixel (0,0) in this case\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "gt = ds.GetGeoTransform()\n",
    "minx = gt[0]\n",
    "miny = gt[3] + width*gt[4] + height*gt[5] \n",
    "maxx = gt[0] + width*gt[1] + height*gt[2]\n",
    "maxy = gt[3]\n",
    "\n",
    "#get the coordinates in lat long\n",
    "latlong1 = transform.TransformPoint(minx,miny)\n",
    "print(latlong1)\n",
    "latlong2 = transform.TransformPoint(minx,maxy)\n",
    "print(latlong2)\n",
    "latlong3 = transform.TransformPoint(maxx,maxy)\n",
    "print(latlong3)\n",
    "latlong4 = transform.TransformPoint(maxx,miny)\n",
    "print(latlong4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "#https://stackoverflow.com/questions/2922532/obtain-latitude-and-longitude-from-a-geotiff-file\n",
    "from osgeo import osr, gdal\n",
    "\n",
    "def get_poly_with_lat_long_from_geotif(geotif_fp):\n",
    "    # Import necessary modules\n",
    "\n",
    "\n",
    "    # get the existing coordinate system\n",
    "    ds = gdal.Open(geotif_fp)\n",
    "\n",
    "    old_cs= osr.SpatialReference()\n",
    "\n",
    "    old_cs.ImportFromWkt(ds.GetProjectionRef())\n",
    "\n",
    "    # create the new coordinate system\n",
    "    nad83_wkt = \"\"\"\n",
    "    GEOGCS[\"NAD83\",\n",
    "        DATUM[\"North_American_Datum_1983\",\n",
    "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
    "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
    "            TOWGS84[0,0,0,0,0,0,0],\n",
    "            AUTHORITY[\"EPSG\",\"6269\"]],\n",
    "        PRIMEM[\"Greenwich\",0,\n",
    "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "        UNIT[\"degree\",0.0174532925199433,\n",
    "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "        AUTHORITY[\"EPSG\",\"4269\"]]\"\"\"\n",
    "\n",
    "    new_cs = osr.SpatialReference()\n",
    "\n",
    "    new_cs .ImportFromWkt(nad83_wkt)\n",
    "\n",
    "    # create a transform object to convert between coordinate systems\n",
    "    transform = osr.CoordinateTransformation(old_cs,new_cs) \n",
    "\n",
    "    #get the point to transform, pixel (0,0) in this case\n",
    "    width = ds.RasterXSize\n",
    "    height = ds.RasterYSize\n",
    "    gt = ds.GetGeoTransform()\n",
    "    minx = gt[0]\n",
    "    miny = gt[3] + width*gt[4] + height*gt[5] \n",
    "    maxx = gt[0] + width*gt[1] + height*gt[2]\n",
    "    maxy = gt[3]\n",
    "\n",
    "    #get the coordinates in lat long\n",
    "    latlong1 = transform.TransformPoint(minx,miny)\n",
    "    print(latlong1)\n",
    "    latlong2 = transform.TransformPoint(minx,maxy)\n",
    "    print(latlong2)\n",
    "    latlong3 = transform.TransformPoint(maxx,maxy)\n",
    "    print(latlong3)\n",
    "    latlong4 = transform.TransformPoint(maxx,miny)\n",
    "    print(latlong4)\n",
    "    \n",
    "    # Create an empty geopandas GeoDataFrame\n",
    "    polydata = gpd.GeoDataFrame()\n",
    "    polydata['geometry'] = None\n",
    "\n",
    "    # Create a Polygon\n",
    "    coords = [(latlong1[0], latlong1[1]), (latlong2[0], latlong2[1]), (latlong3[0], latlong3[1]), (latlong4[0], latlong4[1])]\n",
    "    poly = Polygon(coords)\n",
    "    #polydata.loc[0, 'geometry'] = poly\n",
    "    #polydata.loc[0, 'id'] = 0\n",
    "    #print(polydata)\n",
    "    #newdata = newdata.append(poly, ignore_index=True)\n",
    "    # Determine the output path for the Shapefile\n",
    "    #outfp = r\"/storage/images/charcoal_hearth_hill/images/slope/atestof_just_this_geotiff_border.shp\"\n",
    "\n",
    "    # Write the data into that Shapefile\n",
    "    #polydata.to_file(outfp)\n",
    "    return(poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_poly_with_lat_long_from_geotif(\"/storage/images/charcoal_hearth_hill/images/slope/39_slope.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'latlong1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-85cb64c07e70>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Create a Polygon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mcoords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatlong1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatlong1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlatlong2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatlong2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlatlong3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatlong3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlatlong4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatlong4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mpoly\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolygon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mpolydata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'geometry'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpoly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'latlong1' is not defined"
     ]
    }
   ],
   "source": [
    "# Import necessary modules first\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import fiona\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create an empty geopandas GeoDataFrame\n",
    "polydata = gpd.GeoDataFrame()\n",
    "polydata['geometry'] = None\n",
    "\n",
    "# Create a Polygon\n",
    "coords = [(latlong1[0], latlong1[1]), (latlong2[0], latlong2[1]), (latlong3[0], latlong3[1]), (latlong4[0], latlong4[1])]\n",
    "poly = Polygon(coords)\n",
    "polydata.loc[0, 'geometry'] = poly\n",
    "polydata.loc[0, 'id'] = 0\n",
    "print(polydata)\n",
    "#newdata = newdata.append(poly, ignore_index=True)\n",
    "# Determine the output path for the Shapefile\n",
    "outfp = r\"/storage/images/charcoal_hearth_hill/images/slope/just_this_geotiff_border.shp\"\n",
    "\n",
    "# Write the data into that Shapefile\n",
    "polydata.to_file(outfp)\n",
    "\n",
    "print(\"1\")\n",
    "# Create an empty geopandas GeoDataFrame\n",
    "hearth_data = gpd.GeoDataFrame()\n",
    "hearth_data['geometry'] = None\n",
    "\n",
    "nohearth_data = gpd.GeoDataFrame()\n",
    "nohearth_data['geometry'] = None\n",
    "\n",
    "# Create an empty geopandas GeoDataFrame\n",
    "hearth_data_poly = gpd.GeoDataFrame()\n",
    "hearth_data_poly['geometry'] = None\n",
    "\n",
    "\n",
    "selection = data[0:]\n",
    "\n",
    "for index, row in selection.iterrows():\n",
    "    pt = row['geometry']\n",
    "    #print(row)\n",
    "    #select only points inside the bounds of the geotiff AND are confirmed to be hearths\n",
    "    if(pt.within(poly)==True):\n",
    "        if(row['Confirmed']=='hearth'):\n",
    "            print(pt, pt.within(poly))\n",
    "            hearth_data = hearth_data.append(row, ignore_index=True)\n",
    "            \n",
    "            polygon_half_size = 0.0000895078\n",
    "            polygon_half_size = 0.0001745402\n",
    "            #get the coordinates in lat long\n",
    "            # pp_ = point_poly - the polygon around the points\n",
    "            pp_minx=pt.bounds[0]-polygon_half_size\n",
    "            print(pt.bounds[0])\n",
    "            print(pp_minx)\n",
    "            pp_maxx=pt.bounds[0]+polygon_half_size\n",
    "            pp_miny=pt.bounds[1]-polygon_half_size\n",
    "            pp_maxy=pt.bounds[1]+polygon_half_size\n",
    "            \n",
    "            pp_latlong1 = transform.TransformPoint(pp_minx,pp_miny)\n",
    "            #print(latlong1)\n",
    "            pp_latlong2 = transform.TransformPoint(pp_minx,pp_maxy)\n",
    "            #print(latlong2)\n",
    "            pp_latlong3 = transform.TransformPoint(pp_maxx,pp_maxy)\n",
    "            #print(latlong3)\n",
    "            pp_latlong4 = transform.TransformPoint(pp_maxx,pp_miny)\n",
    "            #print(latlong4)\n",
    "            # Create a Polygon\n",
    "            pp_coords = [(pp_minx, pp_miny), (pp_minx, pp_maxy), (pp_maxx, pp_maxy), (pp_maxx, pp_miny)]\n",
    "            #pp_coords = [(pp_minx, pp_latlong1[1]), (pp_minx, pp_latlong2[1]), (pp_latlong3[0], pp_latlong3[1]), (pp_latlong4[0], pp_latlong4[1])]\n",
    "            print(\"pp_coords\")\n",
    "            print(pp_coords)\n",
    "            ppoly = Polygon(pp_coords)\n",
    "            new_pp_row = {'id':row['id'], 'geometry':ppoly}\n",
    "            #hearth_data_poly.loc[0, 'geometry'] = ppoly\n",
    "            #hearth_data_poly.loc[0, 'id'] = row['id']\n",
    "            hearth_data_poly = hearth_data_poly.append(new_pp_row, ignore_index=True)\n",
    "        if(row['Confirmed']=='nohearth'):\n",
    "            print(pt, pt.within(poly))\n",
    "            nohearth_data = nohearth_data.append(row, ignore_index=True)\n",
    "\n",
    "            \n",
    "#print(\"-----------------------------------\")\n",
    "#print(latlong1,latlong4)\n",
    "#selection = data[0:]\n",
    "#for index, row in selection.iterrows():\n",
    "#    pt = row['geometry']\n",
    "#    if(pt.bounds[0]>=latlong1[0] and pt.bounds[0]<=latlong4[0] and pt.bounds[1]>=latlong1[1] and pt.bounds[1]<=latlong4[1]):\n",
    "#        print(pt, pt.within(poly))\n",
    "#        print(pt.bounds[0])\n",
    "#        #newdata = newdata.append(row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"*** hearth_data\")\n",
    "print(hearth_data)\n",
    "print(\"*** nohearth_data\")\n",
    "print(nohearth_data)\n",
    "print(\"*** hearth_data_poly\")\n",
    "print(hearth_data_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the output path for the Shapefile\n",
    "outfp = r\"/storage/images/charcoal_hearth_hill/images/slope/this_geotiff_hearth.shp\"\n",
    "# Write the data into that Shapefile\n",
    "hearth_data.to_file(outfp)\n",
    "\n",
    "\n",
    "# Determine the output path for the Shapefile\n",
    "outfp = r\"/storage/images/charcoal_hearth_hill/images/slope/this_geotiff_nohearth.shp\"\n",
    "# Write the data into that Shapefile\n",
    "nohearth_data.to_file(outfp)\n",
    "\n",
    "\n",
    "# Determine the output path for the Shapefile\n",
    "outfp = r\"/storage/images/charcoal_hearth_hill/images/slope/this_geotiff_hearth_poly.shp\"\n",
    "# Write the data into that Shapefile\n",
    "hearth_data_poly.to_file(outfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save .tif as .jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "ds = gdal.Open(my_tif)\n",
    "#geoTrans = srcImage.GetGeoTransform()\n",
    "\n",
    "band = ds.GetRasterBand(1)\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "\n",
    "data = band.ReadAsArray(0, 0, width, height)\n",
    "#convert all the bad data\n",
    "data[data==-9999.0] = 0\n",
    "max_value = numpy.max(data)\n",
    "color_multiplier = 255/(max_value-1)\n",
    "print(color_multiplier)\n",
    "data = data*color_multiplier\n",
    "print(data)\n",
    "data_int = np.array(data, dtype='int')\n",
    "print(data_int)\n",
    "#clip = ds.readasarray(ds)\n",
    "data_int = data_int.astype(gdalnumeric.uint8)\n",
    "\n",
    "gdalnumeric.SaveArray(data_int, \"BlueMtHearthforShawnJeff.jpg\", format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Needed for below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def tif_to_jpg(tif_file,output_file_name, output_folder):\n",
    "    #print(tif_file,output_file_name, output_folder)\n",
    "    ds = gdal.Open(tif_file)\n",
    "    #geoTrans = srcImage.GetGeoTransform()\n",
    "\n",
    "    band = ds.GetRasterBand(1)\n",
    "    width = ds.RasterXSize\n",
    "    height = ds.RasterYSize\n",
    "\n",
    "    data = band.ReadAsArray(0, 0, width, height)\n",
    "    #convert all the bad data\n",
    "    data[data==-9999.0] = 0\n",
    "    max_value = numpy.max(data)\n",
    "    color_multiplier = 255/(max_value-1)\n",
    "    #print(color_multiplier)\n",
    "    data = data*color_multiplier\n",
    "    #print(data)\n",
    "    data_int = np.array(data, dtype='int')\n",
    "    #print(data_int)\n",
    "    #clip = ds.readasarray(ds)\n",
    "    data_int = data_int.astype(gdalnumeric.numpy.uint8)\n",
    "\n",
    "    gdalnumeric.SaveArray(data_int, output_folder+output_file_name+\".jpg\", format=\"JPEG\")\n",
    "\n",
    "#https://pcjericks.github.io/py-gdalogr-cookbook/raster_layers.html?highlight=rasterize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this\n",
    "def write_annot(obj_type, obj_annots_dir, obj_f_num, org_f_path,org_f_width,org_f_height,org_f_depth, refPts):\n",
    "    # With credit to: \n",
    "    # https://www.geeksforgeeks.org/reading-writing-text-files-python/\n",
    "    annot_file_path = obj_annots_dir+obj_f_num+'.xml'\n",
    "    annot_file = open(annot_file_path,\"w\") \n",
    "\n",
    "    annot_file.write(\"<annotation>\\n\") \n",
    "    annot_file.write(\"\t<folder>\"+obj_type+\"</folder>\\n\") \n",
    "    annot_file.write(\"\t<filename>\"+obj_f_num+\".jpg</filename>\\n\") \n",
    "    annot_file.write(\"\t<path>\"+org_f_path+\"</path>\\n\") \n",
    "    annot_file.write(\"\t<source>\\n\") \n",
    "    annot_file.write(\"\t\t<database>Muhlenberg_charcoal_hearths</database>\\n\") \n",
    "    annot_file.write(\"\t</source>\\n\") \n",
    "    annot_file.write(\"\t<size>\\n\") \n",
    "    annot_file.write(\"\t\t<width>\"+str(org_f_width)+\"</width>\\n\") \n",
    "    annot_file.write(\"\t\t<height>\"+str(org_f_height)+\"</height>\\n\") \n",
    "    annot_file.write(\"\t\t<depth>\"+str(org_f_depth)+\"</depth>\\n\") \n",
    "    annot_file.write(\"\t</size>\\n\") \n",
    "    annot_file.write(\"\t<segmented>0</segmented>\\n\") \n",
    "    for ocn in range(0,len(refPts)):\n",
    "        refPt = refPts[ocn]\n",
    "        refPtMin = refPt[0]\n",
    "        refPtMax = refPt[1]\n",
    "        \n",
    "        #Sometimes the mouse gets dragged from the bottom to the top, etc\n",
    "        if(refPtMin[1]>refPtMax[1]):\n",
    "            ytemp = refPtMin[1]\n",
    "            refPtMin[1] = refPtMax[1]\n",
    "            refPtMax[1]=ytemp\n",
    "        if(refPtMin[0]>refPtMax[0]):\n",
    "            xtemp = refPtMin[0]\n",
    "            refPtMin[0] = refPtMax[0]\n",
    "            refPtMax[0]=xtemp \n",
    "        \n",
    "        annot_file.write(\"\t<object>\\n\") \n",
    "        annot_file.write(\"\t\t<name>\"+obj_type+\"</name>\\n\") \n",
    "        annot_file.write(\"\t\t<number>\"+str(ocn)+\"</number>\\n\") \n",
    "        annot_file.write(\"\t\t<truncated>0</truncated>\\n\") \n",
    "        annot_file.write(\"\t\t<difficult>0</difficult>\\n\") \n",
    "        annot_file.write(\"\t\t<bndbox>\\n\") \n",
    "        annot_file.write(\"\t\t\t<xmin>\"+str(refPtMin[0])+\"</xmin>\\n\") \n",
    "        annot_file.write(\"\t\t\t<ymin>\"+str(refPtMin[1])+\"</ymin>\\n\") \n",
    "        annot_file.write(\"\t\t\t<xmax>\"+str(refPtMax[0])+\"</xmax>\\n\") \n",
    "        annot_file.write(\"\t\t\t<ymax>\"+str(refPtMax[1])+\"</ymax>\\n\") \n",
    "        annot_file.write(\"\t\t</bndbox>\\n\") \n",
    "        annot_file.write(\"\t</object>\\n\") \n",
    "    annot_file.write(\"</annotation>\\n\") \n",
    "    annot_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note below the Proj4 incantation.\n",
    "# The words of this spell come from the EPSG definition, visible for the CRS in QGIS\n",
    "#NAD83 / Pennsylvania South\n",
    "#Extent\n",
    "#-80.53, 39.71, -74.72, 41.18\n",
    "#Proj4\n",
    "#+proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\n",
    "\n",
    "#See and Thanks to:\n",
    "#https://geog0111.readthedocs.io/en/latest/Chapter7_FittingPhenologyModels.html?highlight=Proj4#selecting-data-from-a-raster-file\n",
    "\n",
    "def convert_coordinates(x_location, y_location,\n",
    "                        #src_transform={'EPSG':32128},\n",
    "                        #dst_transform={'Proj4':\"+proj=lcc +lat_1=41.95 +lat_2=40.88333333333333 +lat_0=40.16666666666666 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"}):\n",
    "                        \n",
    "                       #src_transform={'EPSG':4326},\n",
    "                        #dst_transform={'Proj4':\"+proj=longlat +datum=WGS84 +no_defs\"}):\n",
    "                       #dst_transform={'Proj4':\"+proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"}):\n",
    "    src_transform={'EPSG':32128},\n",
    "    dst_transform={'Proj4':\"+proj=lcc +lat_1=41.95 +lat_2=40.88333333333333 +lat_0=40.16666666666666 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"}):\n",
    "    \"\"\"A function to convert coordinates from one target coordinate\n",
    "    representation to another. The input an output transformation can be given\n",
    "    in either EPSG codes or Proj4 strings, by providing the function with a\n",
    "    dictionary with the desired convention as a key, and with the relevant\n",
    "    codes as its only element.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x_location: float\n",
    "        The x location\n",
    "    y_location: float\n",
    "        The y location\n",
    "    src_transform: dict\n",
    "        A dictionary with keys either \"EPSG\" or \"Proj4\" (anything else throws\n",
    "        an exception) with the description of the **input** projection\n",
    "    dst_transform: dict\n",
    "        A dictionary with keys either \"EPSG\" or \"Proj4\" (anything else throws\n",
    "        an exception) with the description of the **output** projection\n",
    "    Returns\n",
    "    --------\n",
    "\n",
    "    The transformed x and y coordinates\"\"\"\n",
    "    input_coords = osr.SpatialReference()\n",
    "    # In this case, we use EPSG code\n",
    "    try:\n",
    "        input_coords.ImportFromEPSG(src_transform[\"EPSG\"])\n",
    "    except KeyError:\n",
    "        input_coords.ImportFromProj4(src_transform[\"Proj4\"])\n",
    "    except KeyError:\n",
    "        raise ValueError(\"src_transform not dictionary with EPSG/Proj4 keys!\")\n",
    "\n",
    "\n",
    "    output_coords = osr.SpatialReference()\n",
    "    try:\n",
    "        output_coords.ImportFromEPSG(dst_transform[\"EPSG\"])\n",
    "    except KeyError:\n",
    "        output_coords.ImportFromProj4(dst_transform[\"Proj4\"])\n",
    "    except KeyError:\n",
    "        raise ValueError(\"src_transform not dictionary with EPSG/Proj4 keys!\")\n",
    "\n",
    "\n",
    "    transformation = osr.CoordinateTransformation(input_coords,\n",
    "                                                 output_coords)\n",
    "    output_x, output_y, output_z = transformation.TransformPoint(x_location,\n",
    "                                                         y_location)\n",
    "    return output_x, output_y\n",
    "\n",
    "\n",
    "##################################################################\n",
    "# Test function\n",
    "##################################################################\n",
    "\n",
    "#x_location, y_location = 43.3623, -8.4115 # In WGS84\n",
    "\n",
    "#x_location, y_location = -75.7128140898394, 40.771356587287\n",
    "\n",
    "#print (convert_coordinates(x_location, y_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "def get_pixel(raster, point_x, point_y):\n",
    "    \"\"\"Get the pixel for given coordinates (in the raster's convention, not\n",
    "    checked!) for a raster file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raster: string\n",
    "        A GDAL-friendly raster filename\n",
    "    point_x: float\n",
    "        The Easting in the same coordinates as the raster (not checked!)\n",
    "    point_y: float\n",
    "        The Northing in the same coordinates as the raster (not checked!)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The row/column (or column/row, depending on how you define it)\n",
    "    \"\"\"\n",
    "    g = gdal.Open(raster)\n",
    "    if g is None:\n",
    "        raise ValueError(f\"{raster:s} cannot be opened!\")\n",
    "    geoT = g.GetGeoTransform()\n",
    "    inv_geoT = gdal.InvGeoTransform(geoT)\n",
    "    r, c = (gdal.ApplyGeoTransform(inv_geoT, point_x, point_y))\n",
    "    return int(r + 0.5), int(c + 0.5)\n",
    "\n",
    "##################################################################\n",
    "# Test function\n",
    "##################################################################\n",
    "\n",
    "\n",
    "#fname = \"/home/plewis/public_html/geog0111_data/lai_files/\" + \\\n",
    "#              \"MCD15A3H.A2016273.h17v04.006.2016278070708.hdf\"\n",
    "#gdal_fname = 'HDF4_EOS:EOS_GRID:\"%s\":MOD_Grid_MCD15A3H:Fpar_500m' % fname\n",
    "\n",
    "#gdal_fname =\"BlueMtHearthforShawnJeff.tif\"\n",
    "#print (get_pixel(gdal_fname, 771970.4122612458, 161656.97900192798))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-79.94041862482659, 41.345360655348536)\n",
      "(-416703, 133423)\n"
     ]
    }
   ],
   "source": [
    "#/storage/images/charcoal_hearth_hill/images/split_tifs/390819.tif\n",
    "#src_ds.RasterXSize 1024 768\n",
    "#boundary = poly.bounds\n",
    "#-79.94041862482659\n",
    "#41.345360655348536\n",
    "#-79.94006954442658\n",
    "#41.345709735748535\n",
    "#lon,lat -79.94041862482659 41.345360655348536\n",
    "#54 -92229\n",
    "#lon,lat -79.94006954442658 41.345709735748535\n",
    "#84 -92267\n",
    "#boundary = poly.bounds\n",
    "#-79.93842727130712\n",
    "#41.34473854341196\n",
    "#-79.9380781909071\n",
    "#41.345087623811956\n",
    "\n",
    "\n",
    "x_location, y_location = -79.94041862482659, 41.345360655348536\n",
    "\n",
    "print (convert_coordinates(x_location, y_location))\n",
    "\n",
    "gdal_fname =\"/storage/images/charcoal_hearth_hill/images/split_tifs/390819.tif\"\n",
    "cx,cy=convert_coordinates(x_location, y_location)\n",
    "print (get_pixel(gdal_fname,cx,cy ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified version - uses a raster already open to save processing\n",
    "def get_pixel_with_geot(geoT, point_x, point_y):\n",
    "    \"\"\"Get the pixel for given coordinates (in the raster's convention, not\n",
    "    checked!) for a raster file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    geoT: \n",
    "        raster.GetGeoTransform()\n",
    "    point_x: float\n",
    "        The Easting in the same coordinates as the raster (not checked!)\n",
    "    point_y: float\n",
    "        The Northing in the same coordinates as the raster (not checked!)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The row/column (or column/row, depending on how you define it)\n",
    "    \"\"\"\n",
    "    \n",
    "    inv_geoT = gdal.InvGeoTransform(geoT)\n",
    "    r, c = (gdal.ApplyGeoTransform(inv_geoT, point_x, point_y))\n",
    "    return int(r + 0.5), int(c + 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://gis.stackexchange.com/questions/129847/obtain-coordinates-and-corresponding-pixel-values-from-geotiff-using-python-gdal\n",
    "#    #open raster layer\n",
    "src_ds=gdal.Open(my_tif) \n",
    "gt=src_ds.GetGeoTransform()\n",
    "#Get the dimentions of column and row\n",
    "nc   = src_ds.RasterXSize\n",
    "nr   = src_ds.RasterYSize\n",
    "print(nc,nr)\n",
    "gdal.UseExceptions() #so it doesn't print to screen everytime point is outside grid\n",
    "\n",
    "refPts = []      \n",
    "refPt = []\n",
    "#I'm hoping the tifs will be 1452X1091        \n",
    "# Make annotation file for the jpeg from polygons\n",
    "for index, row in hearth_data_poly.iterrows():\n",
    "    poly = row['geometry']\n",
    "    #print(row, row['id'])\n",
    "    #print(poly)\n",
    "    \n",
    "    boundary = poly.bounds\n",
    "    #print(boundary[0])\n",
    "    #print(boundary[1])\n",
    "    #print(boundary[2])\n",
    "    #print(boundary[3])\n",
    "\n",
    "    lon = boundary[0]\n",
    "    lat = boundary[1]\n",
    "    \n",
    "    print(\"lon,lat\",lon, lat)\n",
    "        \n",
    "    cx,cy=convert_coordinates(lon, lat)\n",
    "    p1x,p1y= (get_pixel_with_geot(gt,cx,cy ))\n",
    "    \n",
    "    \n",
    "    print(p1x,p1y)\n",
    "    lon = boundary[2]\n",
    "    lat = boundary[3]\n",
    "    \n",
    "    print(\"lon,lat\",lon, lat)\n",
    "        \n",
    "    cx,cy=convert_coordinates(lon, lat)\n",
    "    p2x,p2y= (get_pixel_with_geot(gt,cx,cy ))\n",
    "    print(p2x,p2y)\n",
    "    #p2y is smaller than p1y so we'll exchange them to keep p1 as the minimum.\n",
    "    ptemp=p1y\n",
    "    p1y=p2y\n",
    "    p2y=ptemp\n",
    "    if(p1x<0):\n",
    "        p1x=0\n",
    "    if(p1y<0):\n",
    "        p1y=0\n",
    "    if(p2x<0):\n",
    "        p2x=0\n",
    "    if(p2y<0):\n",
    "        p2y=0\n",
    "\n",
    "    if(p1x>nc):\n",
    "        p1x=nc\n",
    "    if(p1y>nr):\n",
    "        p1y=nr\n",
    "    if(p2x>nc):\n",
    "        p2x=nc\n",
    "    if(p2y>nr):\n",
    "        p2y=nr\n",
    "     \n",
    "        \n",
    "    refPt = [(p1x, p1y)]\n",
    "    refPt.append((p2x, p2y))\n",
    "    refPts.append(refPt)\n",
    "\n",
    "object_type = 'charcoal_hearth_hill'\n",
    "object_annots_dir = 'C:\\\\a_orgs\\\\carleton\\\\hist3814\\\\R\\\\charcoalhearths_data\\\\'+object_type+'\\\\annots\\\\'\n",
    "write_annot(object_type, object_annots_dir, \"BlueMtHearthforShawnJeff\", \"BlueMtHearthforShawnJeff.jpg\",nc,nr,1, refPts)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://gis.stackexchange.com/questions/92207/split-a-large-geotiff-into-smaller-regions-with-python-and-gdal\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to\n",
    "#https://gis.stackexchange.com/questions/92207/split-a-large-geotiff-into-smaller-regions-with-python-and-gdal\n",
    "import os  \n",
    "import numpy\n",
    "#import gdal\n",
    "from osgeo import gdal, osr\n",
    "import math\n",
    "from itertools import chain\n",
    "#import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "import numpy as np\n",
    "import gdalnumeric\n",
    "\n",
    "def get_extent(dataset):\n",
    "\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "    transform = dataset.GetGeoTransform()\n",
    "    minx = transform[0]\n",
    "    maxx = transform[0] + cols * transform[1] + rows * transform[2]\n",
    "\n",
    "    miny = transform[3] + cols * transform[4] + rows * transform[5]\n",
    "    maxy = transform[3]\n",
    "\n",
    "    return {\n",
    "            \"minX\": str(minx), \"maxX\": str(maxx),\n",
    "            \"minY\": str(miny), \"maxY\": str(maxy),\n",
    "            \"cols\": str(cols), \"rows\": str(rows)\n",
    "            }\n",
    "\n",
    "def create_tiles(minx, miny, maxx, maxy, nw, nh):\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "\n",
    "    matrix = []\n",
    "\n",
    "    for j in range(nw, 0, -1):\n",
    "        for i in range(0, nh):\n",
    "\n",
    "            ulx = minx + (width/nw) * i # 10/5 * 1\n",
    "            uly = miny + (height/nh) * j # 10/5 * 1\n",
    "\n",
    "            lrx = minx + (width/nw) * (i + 1)\n",
    "            lry = miny + (height/nh) * (j - 1)\n",
    "            matrix.append([[ulx, uly], [lrx, lry]])\n",
    "\n",
    "    return matrix\n",
    "\n",
    "\n",
    "\n",
    "def create_standard_tiles(minx, miny, maxx, maxy):\n",
    "    print(\"standard\",minx, miny, maxx, maxy)\n",
    "    width = maxx - minx\n",
    "    height = maxy - miny\n",
    "    \n",
    "    standard_width = 1024\n",
    "    standard_height = 768\n",
    "    \n",
    "    \n",
    "    nw = int(width/standard_width)+1\n",
    "    nh = int(height/standard_height)+1\n",
    "    print(nw,nh)\n",
    "    #print(nw*standard_width,nh*standard_height)\n",
    "    \n",
    "    matrix = []\n",
    "\n",
    "    for j in range(nh, 0, -1):\n",
    "        for i in range(0, nw):\n",
    "\n",
    "            ulx = minx + (standard_width * i) # 10/5 * 1\n",
    "            uly = miny + (standard_height * j) # 10/5 * 1\n",
    "\n",
    "            lrx = minx + (standard_width * (i + 1))\n",
    "            lry = miny + (standard_height * (j - 1))\n",
    "            if(lrx>maxx):\n",
    "                lrx=maxx\n",
    "            if(lrx<minx):\n",
    "                lrx=minx\n",
    "              \n",
    "            if(lry>maxy):\n",
    "                lry=maxy\n",
    "            if(lry<miny):\n",
    "                lry=miny\n",
    "\n",
    "            if(ulx>maxx):\n",
    "                ulx=maxx\n",
    "            if(ulx<minx):\n",
    "                ulx=minx\n",
    "\n",
    "            if(uly>maxy):\n",
    "                uly=maxy\n",
    "            if(uly<miny):\n",
    "                uly=miny\n",
    "\n",
    "            #print(\"matrix:\",ulx, uly,lrx, lry)\n",
    "            matrix.append([[ulx, uly], [lrx, lry],[i,j]])\n",
    "    print(\"standard\",minx, miny, maxx, maxy)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "def split(file_name):\n",
    "    raw_file_name = os.path.splitext(os.path.basename(file_name))[0].replace(\"_downsample\", \"\")\n",
    "    driver = gdal.GetDriverByName('GTiff')\n",
    "    dataset = gdal.Open(file_name)\n",
    "    \n",
    "    \n",
    "    proj_dataset = osr.SpatialReference(wkt=dataset.GetProjection())\n",
    "    print(proj_dataset.GetAttrValue('AUTHORITY',1))\n",
    "    print(proj_dataset)\n",
    "    \n",
    "    \n",
    "    band = dataset.GetRasterBand(1)\n",
    "    transform = dataset.GetGeoTransform()\n",
    "\n",
    "\n",
    "    extent = get_extent(dataset)\n",
    "\n",
    "    cols = int(extent[\"cols\"])\n",
    "    rows = int(extent[\"rows\"])\n",
    "\n",
    "    print (\"Columns: \", cols)\n",
    "    print (\"Rows: \", rows)\n",
    "\n",
    "    minx = float(extent[\"minX\"])\n",
    "    maxx = float(extent[\"maxX\"])\n",
    "    miny = float(extent[\"minY\"])\n",
    "    maxy = float(extent[\"maxY\"])\n",
    "    \n",
    "    width = int(maxx - minx)\n",
    "    height = int(maxy - miny)\n",
    "\n",
    "    nw = int(width/1024)+1\n",
    "    nh = int(height/768)+1\n",
    "    \n",
    "    #******\n",
    "    # make a polygon for the area and see what points are in the whole area.\n",
    "    #get the coordinates in lat long\n",
    "\n",
    "    # Create an empty geopandas GeoDataFrame\n",
    "    area_hearth_data = gpd.GeoDataFrame()\n",
    "    area_hearth_data['geometry'] = None\n",
    "    area_poly=get_poly_with_lat_long_from_geotif(file_name)\n",
    "    # Read file using gpd.read_file()\n",
    "    all_hearth_data = gpd.read_file(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Shapefiles_5-20-2020/Charcoal-Hearths.shp\")\n",
    "    selection = all_hearth_data[0:]\n",
    "    #print(selection)\n",
    "    for index, row in selection.iterrows():\n",
    "        #print(\"for index, row in selection.iterrows():\")\n",
    "        pt = row['geometry']\n",
    "        #print(row)\n",
    "        #select only points inside the bounds of the geotiff AND are confirmed to be hearths\n",
    "        if(pt.within(area_poly)==True):\n",
    "            #print(\"if(pt.within(tif_poly)==True):\")\n",
    "            area_hearth_data = area_hearth_data.append(row, ignore_index=True)\n",
    "    \n",
    "    # Determine the output path for the Shapefile\n",
    "    outfp = r\"area_\"+str(raw_file_name[:2])+\"_hearth.shp\"\n",
    "    # Write the data into that Shapefile\n",
    "    area_hearth_data.to_file(outfp)\n",
    "    #*************************8\n",
    "    output_path = os.path.join(\"data\", raw_file_name)\n",
    "    if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "    #print (\"GCD\", math.gcd(round(width, 0), round(height, 0)))\n",
    "    #print (\"Width\", width)\n",
    "    #print (\"height\", height)\n",
    "\n",
    "    # Polygons to reflect the tiles\n",
    "    # Create an empty geopandas GeoDataFrame\n",
    "    tile_boundary_poly = gpd.GeoDataFrame()\n",
    "    tile_boundary_poly['geometry'] = None\n",
    "\n",
    "    #tiles = create_tiles(minx, miny, maxx, maxy, nw,nh)\n",
    "    tiles = create_standard_tiles(minx, miny, maxx, maxy)\n",
    "    transform = dataset.GetGeoTransform()\n",
    "    xOrigin = transform[0]\n",
    "    yOrigin = transform[3]\n",
    "    pixelWidth = transform[1]\n",
    "    pixelHeight = -transform[5]\n",
    "\n",
    "    #print (xOrigin, yOrigin)\n",
    "\n",
    "    srs = osr.SpatialReference()\n",
    "    srs.ImportFromEPSG(32128)\n",
    "    #srs.ImportFromEPSG(4326)\n",
    "    #dst_ds.SetProjection( srs.ExportToWkt() )\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    tile_num = 0\n",
    "    for tile in tiles:\n",
    "        #print (tile)\n",
    "\n",
    "        minx = tile[0][0]\n",
    "        maxx = tile[1][0]\n",
    "        miny = tile[1][1]\n",
    "        maxy = tile[0][1]\n",
    "        tilex = \"00\"+str(tile[2][0])\n",
    "        tilex = tilex[-2:]\n",
    "        tiley = \"00\"+str(tile[2][1])\n",
    "        tiley = tiley[-2:]\n",
    "        \n",
    "        \n",
    "        \n",
    "        p1 = (minx, maxy)\n",
    "        p2 = (maxx, miny)\n",
    "\n",
    "        i1 = int((p1[0] - xOrigin) / pixelWidth)\n",
    "        j1 = int((yOrigin - p1[1])  / pixelHeight)\n",
    "        i2 = int((p2[0] - xOrigin) / pixelWidth)\n",
    "        j2 = int((yOrigin - p2[1]) / pixelHeight)\n",
    "\n",
    "        #print (i1, j1)\n",
    "        #print (i2, j2)\n",
    "\n",
    "        new_cols = i2-i1\n",
    "        new_rows = j2-j1\n",
    "\n",
    "        data = band.ReadAsArray(i1, j1, new_cols, new_rows)\n",
    "        #print(\"data\",data.mean(),data)\n",
    "        #if len(list(set(chain(*data))))<3:\n",
    "        if(np.all(data==data[0])):\n",
    "            print(\"\")\n",
    "            #print(\"data.mean\",data.mean())\n",
    "        else:\n",
    "            #print(\"data.mean.too\",data.mean())\n",
    "            \n",
    "            new_x = xOrigin + i1*pixelWidth\n",
    "            new_y = yOrigin - j1*pixelHeight\n",
    "\n",
    "            #print (new_x, new_y)\n",
    "\n",
    "            new_transform = (new_x, transform[1], transform[2], new_y, transform[4], transform[5])\n",
    "            output_file_name = raw_file_name[:2] + tilex + tiley\n",
    "            output_file_base = output_file_name + \".tif\"\n",
    "            #output_file = os.path.join(\"/storage/images/charcoal_hearth_hill/images/split_tifs\", raw_file_name, output_file_base)\n",
    "            #output_file = os.path.join(\"/storage/images/charcoal_hearth_hill/images/split_tifs\", raw_file_name, output_file_base)\n",
    "            output_file = \"/storage/images/charcoal_hearth_hill/images/split_tifs/\"+output_file_base\n",
    "\n",
    "            dst_ds = driver.Create(output_file,\n",
    "                                   new_cols,\n",
    "                                   new_rows,\n",
    "                                   1,\n",
    "                                   gdal.GDT_Float32)\n",
    "\n",
    "            #writing output raster\n",
    "            dst_ds.GetRasterBand(1).WriteArray( data )\n",
    "            dst_ds.SetProjection( srs.ExportToWkt() )\n",
    "            dst_ds.SetGeoTransform(new_transform)\n",
    "            tif_metadata = {\n",
    "                \"minX\": str(minx), \"maxX\": str(maxx),\n",
    "                \"minY\": str(miny), \"maxY\": str(maxy)\n",
    "            }\n",
    "            dst_ds.SetMetadata(tif_metadata)\n",
    "\n",
    "            \n",
    "#path = r\"/storage/images/charcoal_hearth_hill/images/slope/39_slope.tif\"\n",
    "#d = gdal.Open(path)\n",
    "#proj = osr.SpatialReference(wkt=d.GetProjection())\n",
    "#print(proj.GetAttrValue('AUTHORITY',1))\n",
    "#print(proj)\n",
    "\n",
    "            #setting extension of output raster\n",
    "            # top left x, w-e pixel resolution, rotation, top left y, rotation, n-s pixel resolution\n",
    "            #dst_ds.SetGeoTransform(new_transform)\n",
    "\n",
    "            #wkt = dataset.GetProjection()\n",
    "\n",
    "            # setting spatial reference of output raster\n",
    "            #srs = osr.SpatialReference()\n",
    "            #srs.ImportFromWkt(wkt)\n",
    "            #dst_ds.SetProjection( srs.ExportToWkt() )\n",
    "\n",
    "            dst_ds = None            \n",
    "\n",
    "            #make a polygon for this tile\n",
    "            tpoly = get_poly_with_lat_long_from_geotif(output_file)\n",
    "            new_tp_row = {'id':tile_num, 'geometry':tpoly}\n",
    "            tile_boundary_poly = tile_boundary_poly.append(new_tp_row, ignore_index=True)\n",
    "            \n",
    "            #Save .jpg\n",
    "            # close tif before re-opening it and saving as jpg\n",
    "            # The jpg is to be consumed by the model.\n",
    "            tif_to_jpg(output_file,output_file_name,\"/storage/images/charcoal_hearth_hill/images/jpgs/\")\n",
    "            #/storage/images/charcoal_hearth_hill/images_training/\n",
    "            #Are there points inside the geotiff?\n",
    "            #annotate_tif_if_it_has_hearths(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Shapefiles_5-20-2020/Charcoal-Hearths.shp\",tpoly,output_file,output_file_name)\n",
    "            annotate_tif_if_it_has_hearths(area_hearth_data,tpoly,output_file,output_file_name)\n",
    "            \n",
    "            #We need to refine to handle points on the border\n",
    "            \n",
    "        #Close output raster dataset\n",
    "        dst_ds = None\n",
    "\n",
    "        tile_num += 1\n",
    "\n",
    "    dataset = None\n",
    "    \n",
    "    # Determine the output path for the Shapefile\n",
    "    outfp = r\"a_tile_boundary.shp\"\n",
    "    # Write the data into that Shapefile\n",
    "    tile_boundary_poly.to_file(outfp)\n",
    "    #print(tile_boundary_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdal\n",
    "from osgeo import ogr\n",
    "def get_pixel_with_geot(geoT, point_x, point_y):\n",
    "    \"\"\"Get the pixel for given coordinates (in the raster's convention, not\n",
    "    checked!) for a raster file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    raster: string\n",
    "        A GDAL-friendly raster filename\n",
    "    point_x: float\n",
    "        The Easting in the same coordinates as the raster (not checked!)\n",
    "    point_y: float\n",
    "        The Northing in the same coordinates as the raster (not checked!)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The row/column (or column/row, depending on how you define it)\n",
    "    \"\"\"\n",
    "    #g = gdal.Open(raster)\n",
    "    #if g is None:\n",
    "    #    raise ValueError(f\"{raster:s} cannot be opened!\")\n",
    "    #geoT = open_raster.GetGeoTransform()\n",
    "    inv_geoT = gdal.InvGeoTransform(geoT)\n",
    "    r, c = (gdal.ApplyGeoTransform(inv_geoT, point_x, point_y))\n",
    "    return int(r + 0.5), int(c + 0.5)\n",
    "\n",
    "def annotate_tif_if_it_has_hearths(area_hearth_data, tif_poly, tif_fp, annot_file_name):\n",
    "    #print(\"annotate_tif_if_it_has_hearths\",area_hearth_data, tif_poly, tif_fp, annot_file_name)\n",
    "    # Set filepath (fix path relative to yours)\n",
    "    #fp = \"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Shapefiles_5-20-2020/Charcoal-Hearths.shp\"\n",
    "\n",
    "\n",
    "    # Create an empty geopandas GeoDataFrame\n",
    "    hearth_data = gpd.GeoDataFrame()\n",
    "    hearth_data['geometry'] = None\n",
    "    hearth_data.crs = {'init':'epsg:4326'}\n",
    "\n",
    "    # Create an empty geopandas GeoDataFrame\n",
    "    hearth_data_poly = gpd.GeoDataFrame()\n",
    "    hearth_data_poly['geometry'] = None\n",
    "    hearth_data_poly.crs = {'init':'epsg:4326'}\n",
    "\n",
    "    selection = area_hearth_data[0:]\n",
    "    point_count=0\n",
    "    \n",
    "    print(tif_fp)\n",
    "    src_ds=gdal.Open(tif_fp) \n",
    "    gt=src_ds.GetGeoTransform()\n",
    "    \n",
    "    #old_cs= osr.SpatialReference()\n",
    "    #old_cs.ImportFromWkt(src_ds.GetProjectionRef())\n",
    "\n",
    "    # create the new coordinate system\n",
    "    #nad83_wkt = \"\"\"\n",
    "    #GEOGCS[\"NAD83\",\n",
    "    #    DATUM[\"North_American_Datum_1983\",\n",
    "    #        SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
    "    #            AUTHORITY[\"EPSG\",\"7019\"]],\n",
    "    #        TOWGS84[0,0,0,0,0,0,0],\n",
    "    #        AUTHORITY[\"EPSG\",\"6269\"]],\n",
    "    #    PRIMEM[\"Greenwich\",0,\n",
    "    #        AUTHORITY[\"EPSG\",\"8901\"]],\n",
    "    #    UNIT[\"degree\",0.0174532925199433,\n",
    "    #        AUTHORITY[\"EPSG\",\"9122\"]],\n",
    "    #    AUTHORITY[\"EPSG\",\"4269\"]]\"\"\"\n",
    "\n",
    "    #new_cs = osr.SpatialReference()\n",
    "    #new_cs .ImportFromWkt(nad83_wkt)\n",
    "\n",
    "    # create a transform object to convert between coordinate systems\n",
    "    #transform = osr.CoordinateTransformation(old_cs,new_cs)\n",
    "    \n",
    "    target = osr.SpatialReference(wkt=src_ds.GetProjection())\n",
    "    source = osr.SpatialReference()\n",
    "    #source.ImportFromEPSG(4326)\n",
    "    source.ImportFromEPSG(32128)\n",
    "    target.ImportFromEPSG(32128)\n",
    "    transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "    for index, row in selection.iterrows():\n",
    "        #print(\"for index, row in selection.iterrows():\")\n",
    "        pt = row['geometry']\n",
    "        #print(row)\n",
    "        #select only points inside the bounds of the geotiff AND are confirmed to be hearths\n",
    "        if(pt.within(tif_poly)==True):\n",
    "            #print(\"if(pt.within(tif_poly)==True):\")\n",
    "            point_count=point_count+1\n",
    "            #print(pt, pt.within(tif_poly))\n",
    "            hearth_data = hearth_data.append(row, ignore_index=True)\n",
    "            \n",
    "            polygon_half_size = 0.0000895078\n",
    "            polygon_half_size = 0.0001745402\n",
    "            #get the coordinates in lat long\n",
    "            # pp_ = point_poly - the polygon around the points\n",
    "            pp_minx=pt.bounds[0]-polygon_half_size\n",
    "            #print(pt.bounds[0])\n",
    "            #print(pp_minx)\n",
    "            pp_maxx=pt.bounds[0]+polygon_half_size\n",
    "            pp_miny=pt.bounds[1]-polygon_half_size\n",
    "            pp_maxy=pt.bounds[1]+polygon_half_size\n",
    "            \n",
    "            pp_latlong1 = transform.TransformPoint(pp_minx,pp_miny)\n",
    "            #print(\"latlong1\",latlong1)\n",
    "            print(\"pp_minx\",pp_minx)\n",
    "            pp_latlong2 = transform.TransformPoint(pp_minx,pp_maxy)\n",
    "            #print(latlong2)\n",
    "            pp_latlong3 = transform.TransformPoint(pp_maxx,pp_maxy)\n",
    "            #print(latlong3)\n",
    "            pp_latlong4 = transform.TransformPoint(pp_maxx,pp_miny)\n",
    "            #print(latlong4)\n",
    "            # Create a Polygon\n",
    "            pp_coords = [(pp_minx, pp_miny), (pp_minx, pp_maxy), (pp_maxx, pp_maxy), (pp_maxx, pp_miny)]\n",
    "            #pp_coords = [(pp_minx, pp_latlong1[1]), (pp_minx, pp_latlong2[1]), (pp_latlong3[0], pp_latlong3[1]), (pp_latlong4[0], pp_latlong4[1])]\n",
    "            #print(\"pp_coords\")\n",
    "            #print(pp_coords)\n",
    "            ppoly = Polygon(pp_coords)\n",
    "            new_pp_row = {'id':row['id'], 'geometry':ppoly}\n",
    "            #hearth_data_poly.loc[0, 'geometry'] = ppoly\n",
    "            #hearth_data_poly.loc[0, 'id'] = row['id']\n",
    "            hearth_data_poly = hearth_data_poly.append(new_pp_row, ignore_index=True)\n",
    "    #Do we have points inside this tif?  If so, annotate and copy>0\n",
    "    if(point_count)>0:\n",
    "        \n",
    "    \n",
    "        hearth_data_poly = hearth_data_poly.to_crs(epsg=32128)\n",
    "        hearth_data = hearth_data.to_crs(epsg=32128)\n",
    "        \n",
    "    \n",
    "        #Write out shp files for diagnostics\n",
    "        outfp_base = tif_fp[:-4]\n",
    "        outfp = outfp_base+\"_hearth_data_poly.shp\"\n",
    "        # Write the data into that Shapefile\n",
    "        hearth_data_poly.to_file(outfp)\n",
    "        outfp = outfp_base+\"_hearth_data.shp\"\n",
    "        # Write the data into that Shapefile\n",
    "        hearth_data.to_file(outfp)\n",
    "        \n",
    "        \n",
    "        print(\"****\")\n",
    "\n",
    "        #Get the dimentions of column and row\n",
    "        nc   = src_ds.RasterXSize\n",
    "        nr   = src_ds.RasterYSize\n",
    "        print(\"src_ds.RasterXSize\", nc,nr)\n",
    "        gdal.UseExceptions() #so it doesn't print to screen everytime point is outside grid\n",
    "        \n",
    "        #target = osr.SpatialReference(wkt=src_ds.GetProjection())\n",
    "        #source = osr.SpatialReference()\n",
    "        #source.ImportFromEPSG(4326)\n",
    "        #transform = osr.CoordinateTransformation(source, target)\n",
    "        \n",
    "        \n",
    "\n",
    "        refPts = []      \n",
    "        refPt = []\n",
    "        #I'm hoping the tifs will be 1024X768        \n",
    "        # Make annotation file for the jpeg from polygons\n",
    "        for index, row in hearth_data_poly.iterrows():\n",
    "            poly = row['geometry']\n",
    "            #print(row, row['id'])\n",
    "            #print(poly)\n",
    "            \n",
    "            boundary = poly.bounds\n",
    "            print(\"boundary = poly.bounds\")\n",
    "            print(boundary[0])\n",
    "            print(boundary[1])\n",
    "            print(boundary[2])\n",
    "            print(boundary[3])\n",
    "\n",
    "            lon = boundary[0]\n",
    "            lat = boundary[1]\n",
    "    \n",
    "            print(\"lon,lat\",lon, lat)\n",
    "      \n",
    "            point = ogr.Geometry(ogr.wkbPoint)\n",
    "            point.AddPoint(lon, lat)\n",
    "            point.Transform(transform)\n",
    "\n",
    "            #p1x,p1y = world_to_pixel(ds.GetGeoTransform(), point.GetX(), point.GetY())\n",
    "            p1x,p1y = get_pixel_with_geot(gt, point.GetX(), point.GetY())\n",
    "            print(\"p1\",point.GetX(), point.GetY(),p1x,p1y)\n",
    "        \n",
    "            #cx,cy=convert_coordinates(lon, lat)\n",
    "            #p1x,p1y= (get_pixel_with_geot(gt,cx,cy ))\n",
    "    \n",
    "   \n",
    "\n",
    "            lon = boundary[2]\n",
    "            lat = boundary[3]\n",
    "    \n",
    "            print(\"lon,lat\",lon, lat)\n",
    "        \n",
    "            #cx,cy=convert_coordinates(lon, lat)\n",
    "            #p2x,p2y= (get_pixel_with_geot(gt,cx,cy ))\n",
    "            point = ogr.Geometry(ogr.wkbPoint)\n",
    "            point.AddPoint(lon, lat)\n",
    "            point.Transform(transform)\n",
    "\n",
    "            #p2x,p2y = world_to_pixel(ds.GetGeoTransform(), point.GetX(), point.GetY())\n",
    "            p2x,p2y = get_pixel_with_geot(gt, point.GetX(), point.GetY())\n",
    "            print(\"p2\",point.GetX(), point.GetY(),p2x,p2y)\n",
    "\n",
    "            \n",
    "\n",
    "            #p2y is smaller than p1y so we'll exchange them to keep p1 as the minimum.\n",
    "            ptemp=p1y\n",
    "            p1y=p2y\n",
    "            p2y=ptemp\n",
    "            if(p1x<0):\n",
    "                p1x=0\n",
    "            if(p1y<0):\n",
    "                p1y=0\n",
    "            if(p2x<0):\n",
    "                p2x=0\n",
    "            if(p2y<0):\n",
    "                p2y=0\n",
    "\n",
    "            if(p1x>nc):\n",
    "                p1x=nc\n",
    "            if(p1y>nr):\n",
    "                p1y=nr\n",
    "            if(p2x>nc):\n",
    "                p2x=nc\n",
    "            if(p2y>nr):\n",
    "                p2y=nr\n",
    "     \n",
    "        \n",
    "            refPt = [(p1x, p1y)]\n",
    "            refPt.append((p2x, p2y))\n",
    "            refPts.append(refPt)\n",
    "\n",
    "        object_type = 'charcoal_hearth_hill'\n",
    "        object_annots_dir = '/storage/images/'+object_type+'/annots/'\n",
    "        write_annot(object_type, object_annots_dir, annot_file_name, annot_file_name+\".jpg\",nc,nr,1, refPts)\n",
    "        tif_to_jpg(tif_fp,annot_file_name,\"/storage/images/charcoal_hearth_hill/images_training/\")\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26918\n",
      "PROJCS[\"NAD83 / UTM zone 18N\",\n",
      "    GEOGCS[\"NAD83\",\n",
      "        DATUM[\"North_American_Datum_1983\",\n",
      "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
      "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
      "            TOWGS84[0,0,0,0,0,0,0],\n",
      "            AUTHORITY[\"EPSG\",\"6269\"]],\n",
      "        PRIMEM[\"Greenwich\",0,\n",
      "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
      "        UNIT[\"degree\",0.0174532925199433,\n",
      "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
      "        AUTHORITY[\"EPSG\",\"4269\"]],\n",
      "    PROJECTION[\"Transverse_Mercator\"],\n",
      "    PARAMETER[\"latitude_of_origin\",0],\n",
      "    PARAMETER[\"central_meridian\",-75],\n",
      "    PARAMETER[\"scale_factor\",0.9996],\n",
      "    PARAMETER[\"false_easting\",500000],\n",
      "    PARAMETER[\"false_northing\",0],\n",
      "    UNIT[\"metre\",1,\n",
      "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
      "    AXIS[\"Easting\",EAST],\n",
      "    AXIS[\"Northing\",NORTH],\n",
      "    AUTHORITY[\"EPSG\",\"26918\"]]\n",
      "Columns:  7500\n",
      "Rows:  6000\n",
      "(-75.99243820721493, 40.17362215473075, 0.0)\n",
      "(-75.99322666674416, 40.227670959849085, 0.0)\n",
      "(-75.90508136838083, 40.22839385099543, 0.0)\n",
      "(-75.90436285741474, 40.174343672980704, 0.0)\n",
      "standard 415500.0 4447500.0 423000.0 4453500.0\n",
      "8 8\n",
      "standard 415500.0 4447500.0 423000.0 4453500.0\n",
      "(-83.20310968897772, 76.89501559487823, 0.0)\n",
      "(-83.20426960963304, 76.89918748685307, 0.0)\n",
      "(-83.17407698492444, 76.8996179803271, 0.0)\n",
      "(-83.17292345142322, 76.8954460402389, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520008.tif\n",
      "(-83.17292345142322, 76.8954460402389, 0.0)\n",
      "(-83.17407698492444, 76.8996179803271, 0.0)\n",
      "(-83.14388304010178, 76.90004608277953, 0.0)\n",
      "(-83.14273589459452, 76.89587409484331, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520108.tif\n",
      "(-83.14273589459452, 76.89587409484331, 0.0)\n",
      "(-83.14388304010178, 76.90004608277953, 0.0)\n",
      "(-83.11368778241828, 76.90047179412817, 0.0)\n",
      "(-83.1125470257403, 76.89629975860933, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520208.tif\n",
      "(-83.1125470257403, 76.89629975860933, 0.0)\n",
      "(-83.11368778241828, 76.90047179412817, 0.0)\n",
      "(-83.0834912191291, 76.90089511429126, 0.0)\n",
      "(-83.0823568521111, 76.89672303145524, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520308.tif\n",
      "(-83.0823568521111, 76.89672303145524, 0.0)\n",
      "(-83.0834912191291, 76.90089511429126, 0.0)\n",
      "(-83.05329335749126, 76.90131604318749, 0.0)\n",
      "(-83.05216538095938, 76.89714391329979, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520408.tif\n",
      "(-83.05216538095938, 76.89714391329979, 0.0)\n",
      "(-83.05329335749126, 76.90131604318749, 0.0)\n",
      "(-83.02309420476364, 76.90173458073602, 0.0)\n",
      "(-83.02197261953951, 76.89756240406214, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520508.tif\n",
      "(-83.02197261953951, 76.89756240406214, 0.0)\n",
      "(-83.02309420476364, 76.90173458073602, 0.0)\n",
      "(-82.99289376820708, 76.90215072685648, 0.0)\n",
      "(-82.99177857510769, 76.89797850366196, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520608.tif\n",
      "(-82.99177857510769, 76.89797850366196, 0.0)\n",
      "(-82.99289376820708, 76.90215072685648, 0.0)\n",
      "(-82.98310194602773, 76.90228513585441, 0.0)\n",
      "(-82.98198882554965, 76.89811289763408, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520708.tif\n",
      "(-83.20168277050682, 76.88988037746317, 0.0)\n",
      "(-83.20310968897772, 76.89501559487823, 0.0)\n",
      "(-83.17292345142322, 76.8954460402389, 0.0)\n",
      "(-83.1715043903711, 76.89031076362569, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520007.tif\n",
      "(-83.1715043903711, 76.89031076362569, 0.0)\n",
      "(-83.17292345142322, 76.8954460402389, 0.0)\n",
      "(-83.14273589459452, 76.89587409484331, 0.0)\n",
      "(-83.14132469199389, 76.89073875935847, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520107.tif\n",
      "(-83.14132469199389, 76.89073875935847, 0.0)\n",
      "(-83.14273589459452, 76.89587409484331, 0.0)\n",
      "(-83.1125470257403, 76.89629975860933, 0.0)\n",
      "(-83.11114368261822, 76.89116436457942, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520207.tif\n",
      "(-83.11114368261822, 76.89116436457942, 0.0)\n",
      "(-83.1125470257403, 76.89629975860933, 0.0)\n",
      "(-83.0823568521111, 76.89672303145524, 0.0)\n",
      "(-83.08096136948905, 76.89158757920684, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520307.tif\n",
      "(-83.08096136948905, 76.89158757920684, 0.0)\n",
      "(-83.0823568521111, 76.89672303145524, 0.0)\n",
      "(-83.05216538095938, 76.89714391329979, 0.0)\n",
      "(-83.05077775985322, 76.89200840315954, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520407.tif\n",
      "(-83.05077775985322, 76.89200840315954, 0.0)\n",
      "(-83.05216538095938, 76.89714391329979, 0.0)\n",
      "(-83.02197261953951, 76.89756240406214, 0.0)\n",
      "(-83.02059286095944, 76.89242683635676, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520507.tif\n",
      "(-83.02059286095944, 76.89242683635676, 0.0)\n",
      "(-83.02197261953951, 76.89756240406214, 0.0)\n",
      "(-82.99177857510769, 76.89797850366196, 0.0)\n",
      "(-82.99040668005833, 76.8928428787182, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520607.tif\n",
      "(-82.99040668005833, 76.8928428787182, 0.0)\n",
      "(-82.99177857510769, 76.89797850366196, 0.0)\n",
      "(-82.98198882554965, 76.89811289763408, 0.0)\n",
      "(-82.9806194802191, 76.89297725420268, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520707.tif\n",
      "(-83.20025659762003, 76.88474451891328, 0.0)\n",
      "(-83.20168277050682, 76.88988037746317, 0.0)\n",
      "(-83.1715043903711, 76.89031076362569, 0.0)\n",
      "(-83.17008607082995, 76.8851748458979, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520006.tif\n",
      "(-83.17008607082995, 76.8851748458979, 0.0)\n",
      "(-83.1715043903711, 76.89031076362569, 0.0)\n",
      "(-83.14132469199389, 76.89073875935847, 0.0)\n",
      "(-83.13991422683, 76.88560278277916, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520106.tif\n",
      "(-83.13991422683, 76.88560278277916, 0.0)\n",
      "(-83.14132469199389, 76.89073875935847, 0.0)\n",
      "(-83.11114368261822, 76.89116436457942, 0.0)\n",
      "(-83.10974107285762, 76.88602832947501, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520206.tif\n",
      "(-83.10974107285762, 76.88602832947501, 0.0)\n",
      "(-83.11114368261822, 76.89116436457942, 0.0)\n",
      "(-83.08096136948905, 76.89158757920684, 0.0)\n",
      "(-83.07956661615214, 76.88645148590383, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520306.tif\n",
      "(-83.07956661615214, 76.88645148590383, 0.0)\n",
      "(-83.08096136948905, 76.89158757920684, 0.0)\n",
      "(-83.05077775985322, 76.89200840315954, 0.0)\n",
      "(-83.04939086395477, 76.88687225198447, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520406.tif\n",
      "(-83.04939086395477, 76.88687225198447, 0.0)\n",
      "(-83.05077775985322, 76.89200840315954, 0.0)\n",
      "(-83.02059286095944, 76.89242683635676, 0.0)\n",
      "(-83.01921382350865, 76.88729062763622, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520506.tif\n",
      "(-83.01921382350865, 76.88729062763622, 0.0)\n",
      "(-83.02059286095944, 76.89242683635676, 0.0)\n",
      "(-82.99040668005833, 76.8928428787182, 0.0)\n",
      "(-82.98903550205873, 76.88770661277881, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520606.tif\n",
      "(-82.98903550205873, 76.88770661277881, 0.0)\n",
      "(-82.99040668005833, 76.8928428787182, 0.0)\n",
      "(-82.9806194802191, 76.89297725420268, 0.0)\n",
      "(-82.97925085061544, 76.887840969782, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520706.tif\n",
      "(-83.19883116973392, 76.8796080193579, 0.0)\n",
      "(-83.20025659762003, 76.88474451891328, 0.0)\n",
      "(-83.17008607082995, 76.8851748458979, 0.0)\n",
      "(-83.1686684922195, 76.88003828718479, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520005.tif\n",
      "(-83.1686684922195, 76.88003828718479, 0.0)\n",
      "(-83.17008607082995, 76.8851748458979, 0.0)\n",
      "(-83.13991422683, 76.88560278277916, 0.0)\n",
      "(-83.13850449852575, 76.88046616523464, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520105.tif\n",
      "(-83.13850449852575, 76.88046616523464, 0.0)\n",
      "(-83.13991422683, 76.88560278277916, 0.0)\n",
      "(-83.10974107285762, 76.88602832947501, 0.0)\n",
      "(-83.10833919588453, 76.88089165342538, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520205.tif\n",
      "(-83.10833919588453, 76.88089165342538, 0.0)\n",
      "(-83.10974107285762, 76.88602832947501, 0.0)\n",
      "(-83.07956661615214, 76.88645148590383, 0.0)\n",
      "(-83.07817259152954, 76.88131475167549, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520305.tif\n",
      "(-83.07817259152954, 76.88131475167549, 0.0)\n",
      "(-83.07956661615214, 76.88645148590383, 0.0)\n",
      "(-83.04939086395477, 76.88687225198447, 0.0)\n",
      "(-83.0480046926964, 76.88173545990382, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520405.tif\n",
      "(-83.0480046926964, 76.88173545990382, 0.0)\n",
      "(-83.04939086395477, 76.88687225198447, 0.0)\n",
      "(-83.01921382350865, 76.88729062763622, 0.0)\n",
      "(-83.01783550662262, 76.88215377802975, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520505.tif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-83.01783550662262, 76.88215377802975, 0.0)\n",
      "(-83.01921382350865, 76.88729062763622, 0.0)\n",
      "(-82.98903550205873, 76.88770661277881, 0.0)\n",
      "(-82.98766504054755, 76.88256970597305, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520605.tif\n",
      "(-82.98766504054755, 76.88256970597305, 0.0)\n",
      "(-82.98903550205873, 76.88770661277881, 0.0)\n",
      "(-82.97925085061544, 76.887840969782, 0.0)\n",
      "(-82.97788293617836, 76.88270404450127, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520705.tif\n",
      "\n",
      "(-83.16725165396005, 76.8749010876157, 0.0)\n",
      "(-83.1686684922195, 76.88003828718479, 0.0)\n",
      "(-83.13850449852575, 76.88046616523464, 0.0)\n",
      "(-83.13709550650462, 76.87532890685418, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520104.tif\n",
      "(-83.13709550650462, 76.87532890685418, 0.0)\n",
      "(-83.13850449852575, 76.88046616523464, 0.0)\n",
      "(-83.10833919588453, 76.88089165342538, 0.0)\n",
      "(-83.10693805112557, 76.8757543365598, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520204.tif\n",
      "(-83.10693805112557, 76.8757543365598, 0.0)\n",
      "(-83.10833919588453, 76.88089165342538, 0.0)\n",
      "(-83.07817259152954, 76.88131475167549, 0.0)\n",
      "(-83.07677929505103, 76.87617737665104, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520304.tif\n",
      "(-83.07677929505103, 76.87617737665104, 0.0)\n",
      "(-83.07817259152954, 76.88131475167549, 0.0)\n",
      "(-83.0480046926964, 76.88173545990382, 0.0)\n",
      "(-83.04661924551101, 76.87659802704684, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520404.tif\n",
      "(-83.04661924551101, 76.87659802704684, 0.0)\n",
      "(-83.0480046926964, 76.88173545990382, 0.0)\n",
      "(-83.01783550662262, 76.88215377802975, 0.0)\n",
      "(-83.01645790973744, 76.87701628766659, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520504.tif\n",
      "(-83.01645790973744, 76.87701628766659, 0.0)\n",
      "(-83.01783550662262, 76.88215377802975, 0.0)\n",
      "(-82.98766504054755, 76.88256970597305, 0.0)\n",
      "(-82.98629529496405, 76.87743215843012, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520604.tif\n",
      "(-82.98629529496405, 76.87743215843012, 0.0)\n",
      "(-82.98766504054755, 76.88256970597305, 0.0)\n",
      "(-82.97788293617836, 76.88270404450127, 0.0)\n",
      "(-82.9765157363481, 76.87756647848967, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520704.tif\n",
      "\n",
      "\n",
      "(-83.13568725019064, 76.87019100776706, 0.0)\n",
      "(-83.13709550650462, 76.87532890685418, 0.0)\n",
      "(-83.10693805112557, 76.8757543365598, 0.0)\n",
      "(-83.10553763800795, 76.87061637900752, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520203.tif\n",
      "(-83.10553763800795, 76.87061637900752, 0.0)\n",
      "(-83.10693805112557, 76.8757543365598, 0.0)\n",
      "(-83.07677929505103, 76.87617737665104, 0.0)\n",
      "(-83.07538672614699, 76.87103936095974, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520303.tif\n",
      "(-83.07538672614699, 76.87103936095974, 0.0)\n",
      "(-83.07677929505103, 76.87617737665104, 0.0)\n",
      "(-83.04661924551101, 76.87659802704684, 0.0)\n",
      "(-83.04523452183217, 76.87145995354275, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520403.tif\n",
      "(-83.04523452183217, 76.87145995354275, 0.0)\n",
      "(-83.04661924551101, 76.87659802704684, 0.0)\n",
      "(-83.01645790973744, 76.87701628766659, 0.0)\n",
      "(-83.0150810322898, 76.87187815667595, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520503.tif\n",
      "(-83.0150810322898, 76.87187815667595, 0.0)\n",
      "(-83.01645790973744, 76.87701628766659, 0.0)\n",
      "(-82.98629529496405, 76.87743215843012, 0.0)\n",
      "(-82.98492626474804, 76.87229397027924, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520603.tif\n",
      "(-82.98492626474804, 76.87229397027924, 0.0)\n",
      "(-82.98629529496405, 76.87743215843012, 0.0)\n",
      "(-82.9765157363481, 76.87756647848967, 0.0)\n",
      "(-82.97514925056558, 76.87242827187642, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520703.tif\n",
      "\n",
      "\n",
      "\n",
      "(-83.1041379559595, 76.86547778089775, 0.0)\n",
      "(-83.10553763800795, 76.87061637900752, 0.0)\n",
      "(-83.07538672614699, 76.87103936095974, 0.0)\n",
      "(-83.07399488424835, 76.86590070473079, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520302.tif\n",
      "(-83.07399488424835, 76.86590070473079, 0.0)\n",
      "(-83.07538672614699, 76.87103936095974, 0.0)\n",
      "(-83.04523452183217, 76.87145995354275, 0.0)\n",
      "(-83.04385052109394, 76.86632123952072, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520402.tif\n",
      "(-83.04385052109394, 76.86632123952072, 0.0)\n",
      "(-83.04523452183217, 76.87145995354275, 0.0)\n",
      "(-83.0150810322898, 76.87187815667595, 0.0)\n",
      "(-83.01370487371696, 76.86673938518699, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520502.tif\n",
      "(-83.01370487371696, 76.86673938518699, 0.0)\n",
      "(-83.0150810322898, 76.87187815667595, 0.0)\n",
      "(-82.98492626474804, 76.87229397027924, 0.0)\n",
      "(-82.98355794933995, 76.86715514164955, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520602.tif\n",
      "(-82.98355794933995, 76.86715514164955, 0.0)\n",
      "(-82.98492626474804, 76.87229397027924, 0.0)\n",
      "(-82.97514925056558, 76.87242827187642, 0.0)\n",
      "(-82.97378347827217, 76.86728942479064, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520702.tif\n",
      "(-83.19313689654867, 76.85905561366717, 0.0)\n",
      "(-83.19455935025434, 76.8641946759517, 0.0)\n",
      "(-83.16442019617848, 76.86462476642656, 0.0)\n",
      "(-83.16300557550001, 76.85948564506498, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520001.tif\n",
      "(-83.16300557550001, 76.85948564506498, 0.0)\n",
      "(-83.16442019617848, 76.86462476642656, 0.0)\n",
      "(-83.13427972900851, 76.86505246810252, 0.0)\n",
      "(-83.13287294238349, 76.85991328798977, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520101.tif\n",
      "(-83.13287294238349, 76.85991328798977, 0.0)\n",
      "(-83.13427972900851, 76.86505246810252, 0.0)\n",
      "(-83.1041379559595, 76.86547778089775, 0.0)\n",
      "(-83.1027390044086, 76.8603385423597, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520201.tif\n",
      "(-83.1027390044086, 76.8603385423597, 0.0)\n",
      "(-83.1041379559595, 76.86547778089775, 0.0)\n",
      "(-83.07399488424835, 76.86590070473079, 0.0)\n",
      "(-83.07260376878672, 76.86076140809337, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520301.tif\n",
      "(-83.07260376878672, 76.86076140809337, 0.0)\n",
      "(-83.07399488424835, 76.86590070473079, 0.0)\n",
      "(-83.04385052109394, 76.86632123952072, 0.0)\n",
      "(-83.04246724273106, 76.86118188510993, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520401.tif\n",
      "(-83.04246724273106, 76.86118188510993, 0.0)\n",
      "(-83.04385052109394, 76.86632123952072, 0.0)\n",
      "(-83.01370487371696, 76.86673938518699, 0.0)\n",
      "(-83.01232943345676, 76.86159997332886, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520501.tif\n",
      "(-83.01232943345676, 76.86159997332886, 0.0)\n",
      "(-83.01370487371696, 76.86673938518699, 0.0)\n",
      "(-82.98355794933995, 76.86715514164955, 0.0)\n",
      "(-82.98219034818078, 76.86201567267018, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520601.tif\n",
      "(-82.98219034818078, 76.86201567267018, 0.0)\n",
      "(-82.98355794933995, 76.86715514164955, 0.0)\n",
      "(-82.97378347827217, 76.86728942479064, 0.0)\n",
      "(-82.97241841890991, 76.86214993736151, 0.0)\n",
      "/storage/images/charcoal_hearth_hill/images/split_tifs/520701.tif\n"
     ]
    }
   ],
   "source": [
    "#split(file_name, n)\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/39/39blast2demPAN_DEM.tif\",10)\n",
    "#split(\"/storage/images/charcoal_hearth_hill/images/slope/39_slope.tif\")\n",
    "\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/39/39blast2demPAN_Slope_DEM.tif\")\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/41/41blast2demPAS_Slope_DEM.tif\")\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/43/43blast2demPAS_Slope_DEM.tif\")\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/46/46blast2demPAS_Slope_DEM.tif\")\n",
    "split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/52/52partialDEM_Slope.tif\")\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/55/55blast2demPAN_Slope_DEM.tif\")\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/58/58blast2demPAN_Slope_DEM.tif\")\n",
    "#split(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Lidar_and_Raster_Images_5-20-2020/72/72blast2demPAN_Slope_DEM.tif\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "41blast2demPAS_Slope_DEM\n",
    "\n",
    "file_name = \"/storage/images/charcoal_hearth_hill/images/slope/39_slope.tif\"\n",
    "raw_file_name = os.path.splitext(os.path.basename(file_name))[0].replace(\"_downsample\", \"\")\n",
    "print(raw_file_name)\n",
    "driver = gdal.GetDriverByName('GTiff')\n",
    "dataset = gdal.Open(raw_file_name+\".tif\")\n",
    "band = dataset.GetRasterBand(1)\n",
    "transform = dataset.GetGeoTransform()\n",
    "\n",
    "extent = get_extent(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "annotate_tif_if_it_has_hearths(\"/storage/images/charcoal_hearth_hill/downloads/Weston_Uploads/Shapefiles_5-20-2020/Charcoal-Hearths.shp\",tpoly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy\n",
    "import gdalnumeric\n",
    "ds = gdal.Open(\"/storage/images/charcoal_hearth_hill/images/split_tifs/390024.tif\")\n",
    "#geoTrans = srcImage.GetGeoTransform()\n",
    "\n",
    "band = ds.GetRasterBand(1)\n",
    "width = ds.RasterXSize\n",
    "height = ds.RasterYSize\n",
    "\n",
    "data = band.ReadAsArray(0, 0, width, height)\n",
    "#convert all the bad data\n",
    "data[data==-9999.0] = 0\n",
    "max_value = numpy.max(data)\n",
    "color_multiplier = 255/(max_value-1)\n",
    "print(color_multiplier)\n",
    "data = data*color_multiplier\n",
    "print(data)\n",
    "data_int = np.array(data, dtype='int')\n",
    "print(data_int)\n",
    "#clip = ds.readasarray(ds)\n",
    "data_int = data_int.astype(gdalnumeric.numpy.uint8)\n",
    "\n",
    "gdalnumeric.SaveArray(data_int, \"BlueMtHearthforShawnJeff.jpg\", format=\"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cx,cy=convert_coordinates(-79.94041862482659, 41.345360655348536)\n",
    "print(cx,cy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/storage/images/charcoal_hearth_hill/images/split_tifs/390819.tif\n",
    "#src_ds.RasterXSize 1024 768\n",
    "#boundary = poly.bounds\n",
    "#-79.94041862482659\n",
    "#41.345360655348536\n",
    "#-79.94006954442658\n",
    "#41.345709735748535\n",
    "#lon,lat -79.94041862482659 41.345360655348536\n",
    "#54 -92229\n",
    "#lon,lat -79.94006954442658 41.345709735748535\n",
    "#84 -92267\n",
    "#boundary = poly.bounds\n",
    "#-79.93842727130712\n",
    "#41.34473854341196\n",
    "#-79.9380781909071\n",
    "#41.345087623811956"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32128\n",
      "PROJCS[\"NAD83 / Pennsylvania North\",\n",
      "    GEOGCS[\"NAD83\",\n",
      "        DATUM[\"North_American_Datum_1983\",\n",
      "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
      "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
      "            TOWGS84[0,0,0,0,0,0,0],\n",
      "            AUTHORITY[\"EPSG\",\"6269\"]],\n",
      "        PRIMEM[\"Greenwich\",0,\n",
      "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
      "        UNIT[\"degree\",0.0174532925199433,\n",
      "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
      "        AUTHORITY[\"EPSG\",\"4269\"]],\n",
      "    PROJECTION[\"Lambert_Conformal_Conic_2SP\"],\n",
      "    PARAMETER[\"standard_parallel_1\",41.95],\n",
      "    PARAMETER[\"standard_parallel_2\",40.88333333333333],\n",
      "    PARAMETER[\"latitude_of_origin\",40.16666666666666],\n",
      "    PARAMETER[\"central_meridian\",-77.75],\n",
      "    PARAMETER[\"false_easting\",600000],\n",
      "    PARAMETER[\"false_northing\",0],\n",
      "    UNIT[\"metre\",1,\n",
      "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
      "    AXIS[\"X\",EAST],\n",
      "    AXIS[\"Y\",NORTH],\n",
      "    AUTHORITY[\"EPSG\",\"32128\"]]\n",
      "32128\n",
      "PROJCS[\"NAD83 / Pennsylvania North\",\n",
      "    GEOGCS[\"NAD83\",\n",
      "        DATUM[\"North_American_Datum_1983\",\n",
      "            SPHEROID[\"GRS 1980\",6378137,298.257222101,\n",
      "                AUTHORITY[\"EPSG\",\"7019\"]],\n",
      "            TOWGS84[0,0,0,0,0,0,0],\n",
      "            AUTHORITY[\"EPSG\",\"6269\"]],\n",
      "        PRIMEM[\"Greenwich\",0,\n",
      "            AUTHORITY[\"EPSG\",\"8901\"]],\n",
      "        UNIT[\"degree\",0.0174532925199433,\n",
      "            AUTHORITY[\"EPSG\",\"9122\"]],\n",
      "        AUTHORITY[\"EPSG\",\"4269\"]],\n",
      "    PROJECTION[\"Lambert_Conformal_Conic_2SP\"],\n",
      "    PARAMETER[\"standard_parallel_1\",41.95],\n",
      "    PARAMETER[\"standard_parallel_2\",40.88333333333333],\n",
      "    PARAMETER[\"latitude_of_origin\",40.16666666666666],\n",
      "    PARAMETER[\"central_meridian\",-77.75],\n",
      "    PARAMETER[\"false_easting\",600000],\n",
      "    PARAMETER[\"false_northing\",0],\n",
      "    UNIT[\"metre\",1,\n",
      "        AUTHORITY[\"EPSG\",\"9001\"]],\n",
      "    AXIS[\"X\",EAST],\n",
      "    AXIS[\"Y\",NORTH],\n",
      "    AUTHORITY[\"EPSG\",\"32128\"]]\n"
     ]
    }
   ],
   "source": [
    "import gdal\n",
    "import osr\n",
    "\n",
    "path = r\"/storage/images/charcoal_hearth_hill/images/slope/39_slope.tif\"\n",
    "d = gdal.Open(path)\n",
    "proj = osr.SpatialReference(wkt=d.GetProjection())\n",
    "print(proj.GetAttrValue('AUTHORITY',1))\n",
    "print(proj)\n",
    "\n",
    "\n",
    "\n",
    "path = r\"/storage/images/charcoal_hearth_hill/images/split_tifs/390711.tif\"\n",
    "d = gdal.Open(path)\n",
    "proj = osr.SpatialReference(wkt=d.GetProjection())\n",
    "print(proj.GetAttrValue('AUTHORITY',1))\n",
    "print(proj)\n",
    "\n",
    "\n",
    "#src_transform={'EPSG':32128},\n",
    "#dst_transform={'Proj4':\"+proj=lcc +lat_1=41.95 +lat_2=40.88333333333333 +lat_0=40.16666666666666 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"}):\n",
    "                        \n",
    "                       #src_transform={'EPSG':4326},\n",
    "                       #dst_transform={'Proj4':\"+proj=lcc +lat_1=40.96666666666667 +lat_2=39.93333333333333 +lat_0=39.33333333333334 +lon_0=-77.75 +x_0=600000 +y_0=0 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs\"}):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "945 420\n"
     ]
    }
   ],
   "source": [
    "from osgeo import osr, ogr, gdal\n",
    "\n",
    "\n",
    "def world_to_pixel(geo_matrix, x, y):\n",
    "    \"\"\"\n",
    "    Uses a gdal geomatrix (gdal.GetGeoTransform()) to calculate\n",
    "    the pixel location of a geospatial coordinate\n",
    "    \"\"\"\n",
    "    ul_x= geo_matrix[0]\n",
    "    ul_y = geo_matrix[3]\n",
    "    x_dist = geo_matrix[1]\n",
    "    y_dist = geo_matrix[5]\n",
    "    pixel = int((x - ul_x) / x_dist)\n",
    "    line = -int((ul_y - y) / y_dist)\n",
    "    return pixel, line\n",
    "\n",
    "# Extract target reference from the tiff file\n",
    "ds = gdal.Open(\"/storage/images/charcoal_hearth_hill/images/split_tifs/390711.tif\")\n",
    "target = osr.SpatialReference(wkt=ds.GetProjection())\n",
    "source = osr.SpatialReference()\n",
    "source.ImportFromEPSG(4326)\n",
    "transform = osr.CoordinateTransformation(source, target)\n",
    "\n",
    "point = ogr.Geometry(ogr.wkbPoint)\n",
    "point.AddPoint(-79.94036802242027, 41.28845973774296)\n",
    "point.Transform(transform)\n",
    "\n",
    "x, y = world_to_pixel(ds.GetGeoTransform(), point.GetX(), point.GetY())\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
